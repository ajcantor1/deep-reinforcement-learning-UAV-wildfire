{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting svgpath2mpl\n",
      "  Downloading svgpath2mpl-1.0.0-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (3.5.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (1.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (4.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->svgpath2mpl) (1.14.0)\n",
      "Installing collected packages: svgpath2mpl\n",
      "Successfully installed svgpath2mpl-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install svgpath2mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adamax\n",
    "import random\n",
    "from svgpath2mpl import parse_path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.ndimage import rotate, shift\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from probabilistic_fire_env import ProbabilisticFireEnv\n",
    "from drone_env import DronesEnv\n",
    "from replay_memory import Transition\n",
    "from models.drqn import DRQN\n",
    "from episode_buffer import EpisodeBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = width = 100\n",
    "BATCH_SIZE = 5\n",
    "GAMMA = 0.99\n",
    "INIT_SIZE = 10\n",
    "TARGET_UPDATE = 1000\n",
    "SAVE_POLICY = 100\n",
    "EPISODE_LENGTH = 250\n",
    "TRAIN_FREQ  = 10   # Number of samples to generate between trainings (Should be multiple of 10)\n",
    "PRINT_FREQ  = 100  # Frequency of printing (Should be a multiple of 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_actions = 2\n",
    "screen_height = screen_width = 100\n",
    "channels = 2\n",
    "policy_net = DRQN(device, channels, screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DRQN(device, channels, screen_height, screen_width, n_actions).to(device)\n",
    "steps = 0\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "episode_buffer = EpisodeBuffer()\n",
    "policy_net.train()\n",
    "target_net.eval()\n",
    "episode_length = 128\n",
    "update_counter = 0\n",
    "optimizer = Adamax(policy_net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    \n",
    "    loss = None\n",
    "    \n",
    "    global update_counter\n",
    "    update_counter += 1\n",
    "\n",
    "    episode_batches, epiosde_length = episode_buffer.sample(BATCH_SIZE, episode_length)\n",
    "    \n",
    "    for episode_batch in episode_batches:\n",
    "\n",
    "\n",
    "        batch = Transition(*zip(*episode_batch))\n",
    "\n",
    "        next_states = torch.cat(batch.next_state_vector)\n",
    "        next_belief_map = torch.cat(batch.next_belief_map)\n",
    "\n",
    "        belief_map_batch = torch.cat(batch.belief_map)\n",
    "        state_vector_batch = torch.cat(batch.state_vector)\n",
    "    \n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        hidden_policy = policy_net.init_hidden_state()\n",
    "        hidden_target = target_net.init_hidden_state()\n",
    "\n",
    "        policy_output, _ = policy_net(belief_map_batch, state_vector_batch, hidden_policy)\n",
    "        target_output, _ = target_net(next_belief_map, next_states, hidden_target)\n",
    "\n",
    "        state_action_values = policy_output.gather(1, action_batch)\n",
    "        next_state_values = target_output.max(1)[0].detach()\n",
    "\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "        criterion = nn.SmoothL1Loss().to(device)\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in policy_net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        optimizer.step()\n",
    "\n",
    "        if update_counter % TARGET_UPDATE == 0:\n",
    "            policy_file_path = f'./policy_weights_drqn.pt'\n",
    "            target_file_path = f'./target_weights_drqn.pt'\n",
    "            torch.save(policy_net.state_dict(), policy_file_path)\n",
    "            torch.save(target_net.state_dict(), target_file_path)\n",
    "            print('update target')\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 episodes completed\n",
      "loss None\n",
      "steps done 2140\n",
      "10 episodes completed\n",
      "loss None\n",
      "steps done 5270\n",
      "15 episodes completed\n",
      "loss 1.5806398391723633\n",
      "steps done 9460\n",
      "20 episodes completed\n",
      "loss 0.5534675121307373\n",
      "steps done 13470\n",
      "25 episodes completed\n",
      "loss 1.4399771690368652\n",
      "steps done 17120\n",
      "30 episodes completed\n",
      "loss 0.012638617306947708\n",
      "steps done 20930\n",
      "35 episodes completed\n",
      "loss 0.01372477412223816\n",
      "steps done 24790\n",
      "40 episodes completed\n",
      "loss 1.4912450313568115\n",
      "steps done 29080\n",
      "45 episodes completed\n",
      "loss 0.003751372918486595\n",
      "steps done 33690\n",
      "50 episodes completed\n",
      "loss 0.002313715871423483\n",
      "steps done 37540\n",
      "55 episodes completed\n",
      "loss 0.004201896488666534\n",
      "steps done 41180\n",
      "60 episodes completed\n",
      "loss 0.40921664237976074\n",
      "steps done 45180\n",
      "65 episodes completed\n",
      "loss 0.016253996640443802\n",
      "steps done 49200\n",
      "70 episodes completed\n",
      "loss 0.011843782849609852\n",
      "steps done 53410\n",
      "75 episodes completed\n",
      "loss 2.1556262969970703\n",
      "steps done 56630\n",
      "80 episodes completed\n",
      "loss 2.9586000442504883\n",
      "steps done 60030\n",
      "85 episodes completed\n",
      "loss 0.12390366941690445\n",
      "steps done 63520\n",
      "90 episodes completed\n",
      "loss 0.000877262675203383\n",
      "steps done 67410\n",
      "95 episodes completed\n",
      "loss 0.00022506987443193793\n",
      "steps done 72030\n",
      "100 episodes completed\n",
      "loss 4.30803108215332\n",
      "steps done 75500\n",
      "105 episodes completed\n",
      "loss 0.0012277120258659124\n",
      "steps done 78870\n",
      "110 episodes completed\n",
      "loss 0.003842449514195323\n",
      "steps done 82450\n",
      "115 episodes completed\n",
      "loss 6.38767596683465e-05\n",
      "steps done 86080\n",
      "120 episodes completed\n",
      "loss 0.45401957631111145\n",
      "steps done 89730\n",
      "125 episodes completed\n",
      "loss 0.9830714464187622\n",
      "steps done 94010\n",
      "130 episodes completed\n",
      "loss 0.06376100331544876\n",
      "steps done 98030\n",
      "135 episodes completed\n",
      "loss 0.006968242581933737\n",
      "steps done 102060\n",
      "140 episodes completed\n",
      "loss 0.842616617679596\n",
      "steps done 105820\n",
      "145 episodes completed\n",
      "loss 3.253528484492563e-05\n",
      "steps done 109350\n",
      "150 episodes completed\n",
      "loss 1.4073845148086548\n",
      "steps done 112620\n",
      "155 episodes completed\n",
      "loss 1.225733995437622\n",
      "steps done 117040\n",
      "160 episodes completed\n",
      "loss 1.1650617122650146\n",
      "steps done 121520\n",
      "165 episodes completed\n",
      "loss 0.00032229244243353605\n",
      "steps done 125520\n",
      "170 episodes completed\n",
      "loss 0.000839049054775387\n",
      "steps done 128910\n",
      "175 episodes completed\n",
      "loss 0.00021340264356695116\n",
      "steps done 132840\n",
      "180 episodes completed\n",
      "loss 0.6013734936714172\n",
      "steps done 136560\n",
      "185 episodes completed\n",
      "loss 1.5465319156646729\n",
      "steps done 140470\n",
      "190 episodes completed\n",
      "loss 0.05358808860182762\n",
      "steps done 144220\n",
      "195 episodes completed\n",
      "loss 1.7277971506118774\n",
      "steps done 148320\n",
      "200 episodes completed\n",
      "loss 7.631099288119003e-05\n",
      "steps done 151390\n",
      "205 episodes completed\n",
      "loss 0.00019586851703934371\n",
      "steps done 155140\n",
      "210 episodes completed\n",
      "loss 0.7673889398574829\n",
      "steps done 158310\n",
      "215 episodes completed\n",
      "loss 9.483853500569239e-05\n",
      "steps done 161900\n",
      "220 episodes completed\n",
      "loss 2.220672369003296\n",
      "steps done 165520\n",
      "225 episodes completed\n",
      "loss 0.00032524167909286916\n",
      "steps done 168900\n",
      "230 episodes completed\n",
      "loss 1.431751012802124\n",
      "steps done 172360\n",
      "235 episodes completed\n",
      "loss 0.00026301288744434714\n",
      "steps done 175820\n",
      "240 episodes completed\n",
      "loss 0.0005907241720706224\n",
      "steps done 180190\n",
      "245 episodes completed\n",
      "loss 0.2287473827600479\n",
      "steps done 184000\n",
      "250 episodes completed\n",
      "loss 0.00013269735791254789\n",
      "steps done 188180\n",
      "255 episodes completed\n",
      "loss 0.030341368168592453\n",
      "steps done 192000\n",
      "260 episodes completed\n",
      "loss 0.006030193530023098\n",
      "steps done 195930\n",
      "265 episodes completed\n",
      "loss 7.051691500237212e-05\n",
      "steps done 198830\n",
      "270 episodes completed\n",
      "loss 1.0969854593276978\n",
      "steps done 202870\n",
      "275 episodes completed\n",
      "loss 1.7509076595306396\n",
      "steps done 207430\n",
      "280 episodes completed\n",
      "loss 0.07728540152311325\n",
      "steps done 211620\n",
      "285 episodes completed\n",
      "loss 0.00011783833906520158\n",
      "steps done 214960\n",
      "290 episodes completed\n",
      "loss 4.214677755953744e-05\n",
      "steps done 218520\n",
      "295 episodes completed\n",
      "loss 0.00024370226310566068\n",
      "steps done 221830\n",
      "300 episodes completed\n",
      "loss 0.32868221402168274\n",
      "steps done 225690\n",
      "305 episodes completed\n",
      "loss 0.0010344991460442543\n",
      "steps done 228870\n",
      "310 episodes completed\n",
      "loss 1.7890584468841553\n",
      "steps done 232450\n",
      "315 episodes completed\n",
      "loss 0.0008772370056249201\n",
      "steps done 236460\n",
      "320 episodes completed\n",
      "loss 0.000257998937740922\n",
      "steps done 240650\n",
      "325 episodes completed\n",
      "loss 4.062946391059086e-05\n",
      "steps done 244270\n",
      "330 episodes completed\n",
      "loss 0.5512149333953857\n",
      "steps done 248410\n",
      "335 episodes completed\n",
      "loss 0.1756986379623413\n",
      "steps done 252320\n",
      "340 episodes completed\n",
      "loss 2.0892398357391357\n",
      "steps done 256670\n",
      "345 episodes completed\n",
      "loss 1.333681583404541\n",
      "steps done 260560\n",
      "350 episodes completed\n",
      "loss 0.0003173399600200355\n",
      "steps done 264370\n",
      "355 episodes completed\n",
      "loss 3.780874013900757\n",
      "steps done 268530\n",
      "360 episodes completed\n",
      "loss 8.926434384193271e-05\n",
      "steps done 272380\n",
      "365 episodes completed\n",
      "loss 7.992749306140468e-05\n",
      "steps done 275960\n",
      "370 episodes completed\n",
      "loss 0.9595770835876465\n",
      "steps done 279810\n",
      "375 episodes completed\n",
      "loss 1.1123104095458984\n",
      "steps done 283490\n",
      "380 episodes completed\n",
      "loss 0.01864929124712944\n",
      "steps done 287620\n",
      "385 episodes completed\n",
      "loss 0.007744763512164354\n",
      "steps done 290810\n",
      "390 episodes completed\n",
      "loss 0.00019497824541758746\n",
      "steps done 295090\n",
      "395 episodes completed\n",
      "loss 0.7764549255371094\n",
      "steps done 299260\n",
      "400 episodes completed\n",
      "loss 0.006092180963605642\n",
      "steps done 302710\n",
      "405 episodes completed\n",
      "loss 0.0002037482481682673\n",
      "steps done 307040\n",
      "410 episodes completed\n",
      "loss 0.6812610030174255\n",
      "steps done 310610\n",
      "415 episodes completed\n",
      "loss 0.00030841230181977153\n",
      "steps done 314420\n",
      "420 episodes completed\n",
      "loss 0.634505033493042\n",
      "steps done 318060\n",
      "425 episodes completed\n",
      "loss 1.2082862854003906\n",
      "steps done 321700\n",
      "430 episodes completed\n",
      "loss 0.00024890719214454293\n",
      "steps done 325860\n",
      "435 episodes completed\n",
      "loss 0.008224432356655598\n",
      "steps done 329170\n",
      "440 episodes completed\n",
      "loss 0.14365729689598083\n",
      "steps done 332880\n",
      "445 episodes completed\n",
      "loss 0.00019582785898819566\n",
      "steps done 336750\n",
      "450 episodes completed\n",
      "loss 0.0003673650498967618\n",
      "steps done 340170\n",
      "455 episodes completed\n",
      "loss 1.3102151155471802\n",
      "steps done 344550\n",
      "460 episodes completed\n",
      "loss 1.757974624633789\n",
      "steps done 347900\n",
      "465 episodes completed\n",
      "loss 1.9478561878204346\n",
      "steps done 350860\n",
      "470 episodes completed\n",
      "loss 0.45597541332244873\n",
      "steps done 355480\n",
      "475 episodes completed\n",
      "loss 0.0017742110649123788\n",
      "steps done 359730\n",
      "480 episodes completed\n",
      "loss 0.00013187192962504923\n",
      "steps done 362800\n",
      "485 episodes completed\n",
      "loss 0.5734270215034485\n",
      "steps done 366320\n",
      "490 episodes completed\n",
      "loss 0.10384530574083328\n",
      "steps done 369880\n",
      "495 episodes completed\n",
      "loss 1.5082694292068481\n",
      "steps done 373630\n",
      "500 episodes completed\n",
      "loss 1.7393012046813965\n",
      "steps done 377360\n",
      "505 episodes completed\n",
      "loss 0.004410863388329744\n",
      "steps done 380700\n",
      "510 episodes completed\n",
      "loss 0.00015766950673423707\n",
      "steps done 384180\n",
      "515 episodes completed\n",
      "loss 0.28974249958992004\n",
      "steps done 388040\n",
      "520 episodes completed\n",
      "loss 0.2687598764896393\n",
      "steps done 391590\n",
      "525 episodes completed\n",
      "loss 0.0004462669021449983\n",
      "steps done 395770\n",
      "530 episodes completed\n",
      "loss 0.7224447131156921\n",
      "steps done 399820\n",
      "535 episodes completed\n",
      "loss 0.0012810325715690851\n",
      "steps done 404070\n",
      "540 episodes completed\n",
      "loss 2.462263584136963\n",
      "steps done 408570\n",
      "545 episodes completed\n",
      "loss 0.15928253531455994\n",
      "steps done 413470\n",
      "550 episodes completed\n",
      "loss 0.001541123609058559\n",
      "steps done 417790\n",
      "555 episodes completed\n",
      "loss 0.0004974844050593674\n",
      "steps done 422210\n",
      "560 episodes completed\n",
      "loss 7.666042074561119e-05\n",
      "steps done 426010\n",
      "565 episodes completed\n",
      "loss 2.597979619167745e-05\n",
      "steps done 429930\n",
      "570 episodes completed\n",
      "loss 2.055124521255493\n",
      "steps done 433020\n",
      "575 episodes completed\n",
      "loss 0.01065564900636673\n",
      "steps done 437060\n",
      "580 episodes completed\n",
      "loss 0.0005818872014060616\n",
      "steps done 440120\n",
      "585 episodes completed\n",
      "loss 0.5225043296813965\n",
      "steps done 443850\n",
      "590 episodes completed\n",
      "loss 0.00015042175073176622\n",
      "steps done 447860\n",
      "595 episodes completed\n",
      "loss 1.3305473327636719\n",
      "steps done 451490\n",
      "600 episodes completed\n",
      "loss 0.00026373739819973707\n",
      "steps done 454870\n",
      "605 episodes completed\n",
      "loss 0.0003426216426305473\n",
      "steps done 458300\n",
      "610 episodes completed\n",
      "loss 1.8385767936706543\n",
      "steps done 462770\n",
      "615 episodes completed\n",
      "loss 0.00011549835471669212\n",
      "steps done 466580\n",
      "620 episodes completed\n",
      "loss 0.0001078223212971352\n",
      "steps done 470980\n",
      "625 episodes completed\n",
      "loss 0.47676169872283936\n",
      "steps done 475270\n",
      "630 episodes completed\n",
      "loss 0.06853878498077393\n",
      "steps done 479630\n",
      "635 episodes completed\n",
      "loss 1.7329925298690796\n",
      "steps done 484370\n",
      "640 episodes completed\n",
      "loss 0.11190822720527649\n",
      "steps done 488340\n",
      "645 episodes completed\n",
      "loss 0.08330782502889633\n",
      "steps done 491840\n",
      "650 episodes completed\n",
      "loss 0.0002656337746884674\n",
      "steps done 495480\n",
      "655 episodes completed\n",
      "loss 0.5189019441604614\n",
      "steps done 499970\n",
      "660 episodes completed\n",
      "loss 0.00022245882428251207\n",
      "steps done 503940\n",
      "665 episodes completed\n",
      "loss 1.785305380821228\n",
      "steps done 507640\n",
      "670 episodes completed\n",
      "loss 0.0025964644737541676\n",
      "steps done 511520\n",
      "675 episodes completed\n",
      "loss 1.5525293350219727\n",
      "steps done 514560\n",
      "680 episodes completed\n",
      "loss 1.1246861219406128\n",
      "steps done 518300\n",
      "685 episodes completed\n",
      "loss 2.775718348857481e-05\n",
      "steps done 522250\n",
      "690 episodes completed\n",
      "loss 0.7743210792541504\n",
      "steps done 526280\n",
      "695 episodes completed\n",
      "loss 9.250719449482858e-05\n",
      "steps done 530520\n",
      "700 episodes completed\n",
      "loss 0.7197445034980774\n",
      "steps done 534270\n",
      "705 episodes completed\n",
      "loss 1.134614109992981\n",
      "steps done 539000\n",
      "710 episodes completed\n",
      "loss 0.0020982446148991585\n",
      "steps done 542250\n",
      "715 episodes completed\n",
      "loss 0.22491304576396942\n",
      "steps done 546250\n",
      "720 episodes completed\n",
      "loss 0.0005794730968773365\n",
      "steps done 549830\n",
      "725 episodes completed\n",
      "loss 4.871407145401463e-05\n",
      "steps done 553550\n",
      "730 episodes completed\n",
      "loss 0.0001788235385902226\n",
      "steps done 557540\n",
      "735 episodes completed\n",
      "loss 0.5653696060180664\n",
      "steps done 561420\n",
      "740 episodes completed\n",
      "loss 0.01143231987953186\n",
      "steps done 565110\n",
      "745 episodes completed\n",
      "loss 0.2105204164981842\n",
      "steps done 568870\n",
      "750 episodes completed\n",
      "loss 1.360588550567627\n",
      "steps done 571930\n",
      "755 episodes completed\n",
      "loss 3.6655099391937256\n",
      "steps done 576060\n",
      "760 episodes completed\n",
      "loss 1.942229986190796\n",
      "steps done 579980\n",
      "765 episodes completed\n",
      "loss 0.00024137170112226158\n",
      "steps done 583110\n",
      "770 episodes completed\n",
      "loss 0.05506877601146698\n",
      "steps done 587820\n",
      "775 episodes completed\n",
      "loss 4.431170236784965e-05\n",
      "steps done 592010\n",
      "780 episodes completed\n",
      "loss 2.3390372007270344e-05\n",
      "steps done 596210\n",
      "785 episodes completed\n",
      "loss 0.00023228334612213075\n",
      "steps done 600090\n",
      "790 episodes completed\n",
      "loss 0.04386590048670769\n",
      "steps done 603660\n",
      "795 episodes completed\n",
      "loss 0.028317516669631004\n",
      "steps done 606380\n",
      "800 episodes completed\n",
      "loss 2.5275548978243023e-05\n",
      "steps done 610920\n",
      "805 episodes completed\n",
      "loss 0.0006992009002715349\n",
      "steps done 613820\n",
      "810 episodes completed\n",
      "loss 0.010695270262658596\n",
      "steps done 618220\n",
      "815 episodes completed\n",
      "loss 5.584598329733126e-05\n",
      "steps done 622160\n",
      "820 episodes completed\n",
      "loss 2.017518997192383\n",
      "steps done 626260\n",
      "825 episodes completed\n",
      "loss 2.9104514396749437e-05\n",
      "steps done 629790\n",
      "830 episodes completed\n",
      "loss 4.23330545425415\n",
      "steps done 633310\n",
      "835 episodes completed\n",
      "loss 0.00020014822075609118\n",
      "steps done 637190\n",
      "840 episodes completed\n",
      "loss 0.02881571650505066\n",
      "steps done 640830\n",
      "845 episodes completed\n",
      "loss 1.3750865459442139\n",
      "steps done 644280\n",
      "850 episodes completed\n",
      "loss 7.668185571674258e-05\n",
      "steps done 647440\n",
      "855 episodes completed\n",
      "loss 0.00010300634312443435\n",
      "steps done 651130\n",
      "860 episodes completed\n",
      "loss 1.8806400299072266\n",
      "steps done 655060\n",
      "865 episodes completed\n",
      "loss 0.1745932698249817\n",
      "steps done 658110\n",
      "870 episodes completed\n",
      "loss 5.4807940614409745e-05\n",
      "steps done 661870\n",
      "875 episodes completed\n",
      "loss 0.23609226942062378\n",
      "steps done 665310\n",
      "880 episodes completed\n",
      "loss 0.3875567317008972\n",
      "steps done 668950\n",
      "885 episodes completed\n",
      "loss 0.00279768998734653\n",
      "steps done 672690\n",
      "890 episodes completed\n",
      "loss 0.000340512691764161\n",
      "steps done 676740\n",
      "895 episodes completed\n",
      "loss 0.015503974631428719\n",
      "steps done 680710\n",
      "900 episodes completed\n",
      "loss 0.028735274448990822\n",
      "steps done 684290\n",
      "905 episodes completed\n",
      "loss 0.07670597732067108\n",
      "steps done 688600\n",
      "910 episodes completed\n",
      "loss 0.00011310531408526003\n",
      "steps done 692880\n",
      "915 episodes completed\n",
      "loss 0.0020217786077409983\n",
      "steps done 696070\n",
      "920 episodes completed\n",
      "loss 0.006090383976697922\n",
      "steps done 699580\n",
      "925 episodes completed\n",
      "loss 0.00038599950494244695\n",
      "steps done 702810\n",
      "930 episodes completed\n",
      "loss 2.0866165161132812\n",
      "steps done 707460\n",
      "935 episodes completed\n",
      "loss 0.00025353094679303467\n",
      "steps done 711200\n",
      "940 episodes completed\n",
      "loss 0.000283136178040877\n",
      "steps done 714770\n",
      "945 episodes completed\n",
      "loss 5.950693775957916e-06\n",
      "steps done 719350\n",
      "950 episodes completed\n",
      "loss 2.2205276489257812\n",
      "steps done 723100\n",
      "955 episodes completed\n",
      "loss 9.35940770432353e-05\n",
      "steps done 726800\n",
      "960 episodes completed\n",
      "loss 5.099022382637486e-05\n",
      "steps done 730450\n",
      "965 episodes completed\n",
      "loss 0.11520944535732269\n",
      "steps done 734270\n",
      "970 episodes completed\n",
      "loss 9.06956847757101e-05\n",
      "steps done 738390\n",
      "975 episodes completed\n",
      "loss 1.612499713897705\n",
      "steps done 741960\n",
      "980 episodes completed\n",
      "loss 1.5846133464947343e-05\n",
      "steps done 745420\n",
      "985 episodes completed\n",
      "loss 0.09529521316289902\n",
      "steps done 749050\n",
      "990 episodes completed\n",
      "loss 7.338266732404009e-05\n",
      "steps done 753500\n",
      "995 episodes completed\n",
      "loss 0.0002761688665486872\n",
      "steps done 757740\n",
      "1000 episodes completed\n",
      "loss 0.4589851200580597\n",
      "steps done 761090\n",
      "1005 episodes completed\n",
      "loss 7.891625864431262e-05\n",
      "steps done 765140\n",
      "1010 episodes completed\n",
      "loss 0.15952077507972717\n",
      "steps done 768760\n",
      "update target\n",
      "update target\n",
      "update target\n",
      "update target\n",
      "update target\n",
      "1015 episodes completed\n",
      "loss 0.4728117287158966\n",
      "steps done 772520\n",
      "1020 episodes completed\n",
      "loss 4.663045406341553\n",
      "steps done 775870\n",
      "1025 episodes completed\n",
      "loss 0.001172384712845087\n",
      "steps done 780050\n",
      "1030 episodes completed\n",
      "loss 0.12269072234630585\n",
      "steps done 784030\n",
      "1035 episodes completed\n",
      "loss 0.1670769453048706\n",
      "steps done 787800\n",
      "1040 episodes completed\n",
      "loss 2.4818578822305426e-05\n",
      "steps done 791630\n",
      "1045 episodes completed\n",
      "loss 7.277981785591692e-05\n",
      "steps done 795310\n",
      "1050 episodes completed\n",
      "loss 0.10836061835289001\n",
      "steps done 799220\n",
      "1055 episodes completed\n",
      "loss 0.18197576701641083\n",
      "steps done 802530\n",
      "1060 episodes completed\n",
      "loss 0.00011772126163123176\n",
      "steps done 806010\n",
      "1065 episodes completed\n",
      "loss 0.18214447796344757\n",
      "steps done 809830\n",
      "1070 episodes completed\n",
      "loss 0.0003006087790708989\n",
      "steps done 813280\n",
      "1075 episodes completed\n",
      "loss 0.03359327092766762\n",
      "steps done 816700\n",
      "1080 episodes completed\n",
      "loss 0.00017451553139835596\n",
      "steps done 820610\n",
      "1085 episodes completed\n",
      "loss 0.3923075795173645\n",
      "steps done 824700\n",
      "1090 episodes completed\n",
      "loss 0.00026816263562068343\n",
      "steps done 827970\n",
      "1095 episodes completed\n",
      "loss 0.0004116609343327582\n",
      "steps done 831620\n",
      "1100 episodes completed\n",
      "loss 0.001993065932765603\n",
      "steps done 835150\n",
      "1105 episodes completed\n",
      "loss 2.218922963947989e-05\n",
      "steps done 839020\n",
      "1110 episodes completed\n",
      "loss 0.539876401424408\n",
      "steps done 842610\n",
      "1115 episodes completed\n",
      "loss 0.007799583487212658\n",
      "steps done 845970\n",
      "1120 episodes completed\n",
      "loss 0.002307020826265216\n",
      "steps done 850290\n",
      "1125 episodes completed\n",
      "loss 0.0005795196630060673\n",
      "steps done 853370\n",
      "1130 episodes completed\n",
      "loss 0.2873906195163727\n",
      "steps done 857010\n",
      "1135 episodes completed\n",
      "loss 0.0002672942937351763\n",
      "steps done 861150\n",
      "1140 episodes completed\n",
      "loss 0.17452117800712585\n",
      "steps done 865450\n",
      "1145 episodes completed\n",
      "loss 0.8399975299835205\n",
      "steps done 869200\n",
      "1150 episodes completed\n",
      "loss 0.0012197475880384445\n",
      "steps done 872360\n",
      "1155 episodes completed\n",
      "loss 0.0008446724386885762\n",
      "steps done 876010\n",
      "1160 episodes completed\n",
      "loss 0.00016474383301101625\n",
      "steps done 879890\n",
      "1165 episodes completed\n",
      "loss 0.00022582216479349881\n",
      "steps done 883830\n",
      "1170 episodes completed\n",
      "loss 0.0013220368418842554\n",
      "steps done 888090\n",
      "1175 episodes completed\n",
      "loss 0.4758138060569763\n",
      "steps done 891950\n",
      "1180 episodes completed\n",
      "loss 0.03357889503240585\n",
      "steps done 896450\n",
      "1185 episodes completed\n",
      "loss 0.0003454650577623397\n",
      "steps done 900010\n",
      "1190 episodes completed\n",
      "loss 4.5065287849865854e-05\n",
      "steps done 903970\n",
      "1195 episodes completed\n",
      "loss 0.9124646186828613\n",
      "steps done 907820\n",
      "1200 episodes completed\n",
      "loss 4.461066419025883e-05\n",
      "steps done 911340\n",
      "1205 episodes completed\n",
      "loss 6.160605698823929e-05\n",
      "steps done 914740\n",
      "1210 episodes completed\n",
      "loss 0.00017409815336577594\n",
      "steps done 918610\n",
      "1215 episodes completed\n",
      "loss 0.24194155633449554\n",
      "steps done 922560\n",
      "1220 episodes completed\n",
      "loss 0.00017847080016508698\n",
      "steps done 926860\n",
      "1225 episodes completed\n",
      "loss 0.3585684895515442\n",
      "steps done 931290\n",
      "1230 episodes completed\n",
      "loss 0.005708049051463604\n",
      "steps done 934920\n",
      "1235 episodes completed\n",
      "loss 2.5693373680114746\n",
      "steps done 939290\n",
      "1240 episodes completed\n",
      "loss 0.0016608614241704345\n",
      "steps done 943240\n",
      "1245 episodes completed\n",
      "loss 0.00020735664293169975\n",
      "steps done 946620\n",
      "1250 episodes completed\n",
      "loss 0.3400720953941345\n",
      "steps done 949800\n",
      "1255 episodes completed\n",
      "loss 0.0008408979047089815\n",
      "steps done 953820\n",
      "1260 episodes completed\n",
      "loss 2.3816089630126953\n",
      "steps done 958230\n",
      "1265 episodes completed\n",
      "loss 0.0001747173664625734\n",
      "steps done 961820\n",
      "1270 episodes completed\n",
      "loss 0.00014332792488858104\n",
      "steps done 965350\n",
      "1275 episodes completed\n",
      "loss 0.0003719813539646566\n",
      "steps done 968820\n",
      "1280 episodes completed\n",
      "loss 0.8831237554550171\n",
      "steps done 972450\n",
      "1285 episodes completed\n",
      "loss 1.435271978378296\n",
      "steps done 976030\n",
      "1290 episodes completed\n",
      "loss 1.2312560081481934\n",
      "steps done 979720\n",
      "1295 episodes completed\n",
      "loss 0.0002884608693420887\n",
      "steps done 983860\n",
      "1300 episodes completed\n",
      "loss 0.8693273067474365\n",
      "steps done 987460\n",
      "1305 episodes completed\n",
      "loss 0.00015053956303745508\n",
      "steps done 990240\n",
      "1310 episodes completed\n",
      "loss 0.49935394525527954\n",
      "steps done 993510\n",
      "1315 episodes completed\n",
      "loss 1.1854817867279053\n",
      "steps done 996960\n",
      "1320 episodes completed\n",
      "loss 0.0005861369427293539\n",
      "steps done 1001010\n",
      "1325 episodes completed\n",
      "loss 0.160020112991333\n",
      "steps done 1004580\n",
      "1330 episodes completed\n",
      "loss 0.005071952939033508\n",
      "steps done 1008460\n",
      "1335 episodes completed\n",
      "loss 0.0002293927245773375\n",
      "steps done 1012490\n",
      "1340 episodes completed\n",
      "loss 0.0015429386403411627\n",
      "steps done 1016290\n",
      "1345 episodes completed\n",
      "loss 0.00020064821001142263\n",
      "steps done 1019760\n",
      "1350 episodes completed\n",
      "loss 0.7790735960006714\n",
      "steps done 1023370\n",
      "1355 episodes completed\n",
      "loss 1.7587018013000488\n",
      "steps done 1027350\n",
      "1360 episodes completed\n",
      "loss 1.2876228094100952\n",
      "steps done 1031150\n",
      "1365 episodes completed\n",
      "loss 0.0013709592167288065\n",
      "steps done 1034750\n",
      "1370 episodes completed\n",
      "loss 0.4667283594608307\n",
      "steps done 1038630\n",
      "1375 episodes completed\n",
      "loss 0.0002098291297443211\n",
      "steps done 1041930\n",
      "1380 episodes completed\n",
      "loss 0.0002862535766325891\n",
      "steps done 1045750\n",
      "1385 episodes completed\n",
      "loss 0.0021728468127548695\n",
      "steps done 1050460\n",
      "1390 episodes completed\n",
      "loss 0.00274456525221467\n",
      "steps done 1054760\n",
      "1395 episodes completed\n",
      "loss 0.0002476379740983248\n",
      "steps done 1057950\n",
      "1400 episodes completed\n",
      "loss 0.6612324714660645\n",
      "steps done 1062010\n",
      "1405 episodes completed\n",
      "loss 0.25397253036499023\n",
      "steps done 1065920\n",
      "1410 episodes completed\n",
      "loss 0.0005593962850980461\n",
      "steps done 1069970\n",
      "1415 episodes completed\n",
      "loss 0.00024279794888570905\n",
      "steps done 1074660\n",
      "1420 episodes completed\n",
      "loss 0.000448149919975549\n",
      "steps done 1079470\n",
      "1425 episodes completed\n",
      "loss 0.00012372725177556276\n",
      "steps done 1082830\n",
      "1430 episodes completed\n",
      "loss 0.3725709915161133\n",
      "steps done 1087530\n",
      "1435 episodes completed\n",
      "loss 0.06242353096604347\n",
      "steps done 1090960\n",
      "1440 episodes completed\n",
      "loss 0.0007501213112846017\n",
      "steps done 1095150\n",
      "1445 episodes completed\n",
      "loss 0.007964084856212139\n",
      "steps done 1098380\n",
      "1450 episodes completed\n",
      "loss 0.4137134552001953\n",
      "steps done 1101920\n",
      "1455 episodes completed\n",
      "loss 0.0009652265580371022\n",
      "steps done 1105200\n",
      "1460 episodes completed\n",
      "loss 0.29887136816978455\n",
      "steps done 1108500\n",
      "1465 episodes completed\n",
      "loss 9.543514170218259e-05\n",
      "steps done 1111450\n",
      "1470 episodes completed\n",
      "loss 0.2612580955028534\n",
      "steps done 1114910\n",
      "1475 episodes completed\n",
      "loss 0.0002853424521163106\n",
      "steps done 1119050\n",
      "1480 episodes completed\n",
      "loss 3.3997479476965964e-05\n",
      "steps done 1123160\n",
      "1485 episodes completed\n",
      "loss 0.5864113569259644\n",
      "steps done 1126550\n",
      "1490 episodes completed\n",
      "loss 0.00035021331859752536\n",
      "steps done 1130100\n",
      "1495 episodes completed\n",
      "loss 1.3030202388763428\n",
      "steps done 1133830\n",
      "1500 episodes completed\n",
      "loss 0.00035075272899121046\n",
      "steps done 1137180\n",
      "1505 episodes completed\n",
      "loss 1.6204135417938232\n",
      "steps done 1141430\n",
      "1510 episodes completed\n",
      "loss 0.142258882522583\n",
      "steps done 1144910\n",
      "1515 episodes completed\n",
      "loss 3.848378037218936e-05\n",
      "steps done 1148530\n",
      "1520 episodes completed\n",
      "loss 0.00013597669021692127\n",
      "steps done 1152220\n",
      "1525 episodes completed\n",
      "loss 0.0001429023832315579\n",
      "steps done 1155310\n",
      "1530 episodes completed\n",
      "loss 0.5903431177139282\n",
      "steps done 1158850\n",
      "1535 episodes completed\n",
      "loss 9.672683518147096e-05\n",
      "steps done 1162410\n",
      "1540 episodes completed\n",
      "loss 0.8481959104537964\n",
      "steps done 1165830\n",
      "1545 episodes completed\n",
      "loss 0.24953125417232513\n",
      "steps done 1169080\n",
      "1550 episodes completed\n",
      "loss 6.882127490825951e-05\n",
      "steps done 1173710\n",
      "1555 episodes completed\n",
      "loss 2.351140022277832\n",
      "steps done 1177360\n",
      "1560 episodes completed\n",
      "loss 0.3578256368637085\n",
      "steps done 1181530\n",
      "1565 episodes completed\n",
      "loss 0.04560976102948189\n",
      "steps done 1185510\n",
      "1570 episodes completed\n",
      "loss 0.3077782094478607\n",
      "steps done 1189530\n",
      "1575 episodes completed\n",
      "loss 1.276039481163025\n",
      "steps done 1192810\n",
      "1580 episodes completed\n",
      "loss 1.7058042287826538\n",
      "steps done 1196570\n",
      "1585 episodes completed\n",
      "loss 0.062409717589616776\n",
      "steps done 1199950\n",
      "1590 episodes completed\n",
      "loss 0.00019513838924467564\n",
      "steps done 1203810\n",
      "1595 episodes completed\n",
      "loss 9.003297600429505e-05\n",
      "steps done 1207430\n",
      "1600 episodes completed\n",
      "loss 0.00018894100503530353\n",
      "steps done 1210960\n",
      "1605 episodes completed\n",
      "loss 0.030947361141443253\n",
      "steps done 1214490\n",
      "1610 episodes completed\n",
      "loss 0.00010102101805387065\n",
      "steps done 1218630\n",
      "1615 episodes completed\n",
      "loss 0.00017296399164479226\n",
      "steps done 1221780\n",
      "1620 episodes completed\n",
      "loss 8.124909072648734e-05\n",
      "steps done 1225330\n",
      "1625 episodes completed\n",
      "loss 0.002607903676107526\n",
      "steps done 1229010\n",
      "1630 episodes completed\n",
      "loss 3.8687830965500325e-05\n",
      "steps done 1233100\n",
      "1635 episodes completed\n",
      "loss 0.0006638747290708125\n",
      "steps done 1236640\n",
      "1640 episodes completed\n",
      "loss 8.154095121426508e-05\n",
      "steps done 1240510\n",
      "1645 episodes completed\n",
      "loss 0.000682097626850009\n",
      "steps done 1243930\n",
      "1650 episodes completed\n",
      "loss 0.00020287156803533435\n",
      "steps done 1247560\n",
      "1655 episodes completed\n",
      "loss 0.6048595905303955\n",
      "steps done 1251120\n",
      "1660 episodes completed\n",
      "loss 0.00024287152336910367\n",
      "steps done 1254960\n",
      "1665 episodes completed\n",
      "loss 0.007273489143699408\n",
      "steps done 1258200\n",
      "1670 episodes completed\n",
      "loss 6.736286013619974e-05\n",
      "steps done 1261610\n",
      "1675 episodes completed\n",
      "loss 0.0014360161731019616\n",
      "steps done 1265480\n",
      "1680 episodes completed\n",
      "loss 0.0005458473460748792\n",
      "steps done 1269270\n",
      "1685 episodes completed\n",
      "loss 0.00041532196337357163\n",
      "steps done 1273690\n",
      "1690 episodes completed\n",
      "loss 0.0005799321224913001\n",
      "steps done 1277670\n",
      "1695 episodes completed\n",
      "loss 0.0005171105149202049\n",
      "steps done 1281140\n",
      "1700 episodes completed\n",
      "loss 0.00011556602839846164\n",
      "steps done 1285850\n",
      "1705 episodes completed\n",
      "loss 0.00010787627252284437\n",
      "steps done 1288900\n",
      "1710 episodes completed\n",
      "loss 7.890359120210633e-05\n",
      "steps done 1292940\n",
      "1715 episodes completed\n",
      "loss 5.883170524612069e-05\n",
      "steps done 1297510\n",
      "1720 episodes completed\n",
      "loss 2.216756820678711\n",
      "steps done 1301050\n",
      "1725 episodes completed\n",
      "loss 0.00014347457909025252\n",
      "steps done 1304330\n",
      "1730 episodes completed\n",
      "loss 5.839961158926599e-05\n",
      "steps done 1307720\n",
      "1735 episodes completed\n",
      "loss 0.01763356849551201\n",
      "steps done 1311470\n",
      "1740 episodes completed\n",
      "loss 1.6314723491668701\n",
      "steps done 1315100\n",
      "1745 episodes completed\n",
      "loss 0.4083486795425415\n",
      "steps done 1318970\n",
      "1750 episodes completed\n",
      "loss 0.0009592126589268446\n",
      "steps done 1322340\n",
      "1755 episodes completed\n",
      "loss 0.00010194825154030696\n",
      "steps done 1325490\n",
      "1760 episodes completed\n",
      "loss 0.0017631365917623043\n",
      "steps done 1328980\n",
      "1765 episodes completed\n",
      "loss 0.8408228754997253\n",
      "steps done 1332520\n",
      "1770 episodes completed\n",
      "loss 0.00028793668025173247\n",
      "steps done 1336200\n",
      "1775 episodes completed\n",
      "loss 0.6950241327285767\n",
      "steps done 1340190\n",
      "1780 episodes completed\n",
      "loss 1.2508344650268555\n",
      "steps done 1343940\n",
      "1785 episodes completed\n",
      "loss 0.006772136315703392\n",
      "steps done 1347930\n",
      "1790 episodes completed\n",
      "loss 3.629719140008092e-05\n",
      "steps done 1352100\n",
      "1795 episodes completed\n",
      "loss 0.531430184841156\n",
      "steps done 1355850\n",
      "1800 episodes completed\n",
      "loss 8.530156628694385e-05\n",
      "steps done 1359270\n",
      "1805 episodes completed\n",
      "loss 0.45308810472488403\n",
      "steps done 1362550\n",
      "1810 episodes completed\n",
      "loss 0.00021819313406012952\n",
      "steps done 1366330\n",
      "1815 episodes completed\n",
      "loss 0.010034335777163506\n",
      "steps done 1370350\n",
      "1820 episodes completed\n",
      "loss 2.5854787826538086\n",
      "steps done 1373760\n",
      "1825 episodes completed\n",
      "loss 0.0010249944170936942\n",
      "steps done 1377900\n",
      "1830 episodes completed\n",
      "loss 1.150769591331482\n",
      "steps done 1381390\n",
      "1835 episodes completed\n",
      "loss 0.045987568795681\n",
      "steps done 1384980\n",
      "1840 episodes completed\n",
      "loss 0.14763031899929047\n",
      "steps done 1388600\n",
      "1845 episodes completed\n",
      "loss 0.5743637084960938\n",
      "steps done 1392750\n",
      "1850 episodes completed\n",
      "loss 0.0026399954222142696\n",
      "steps done 1396720\n",
      "1855 episodes completed\n",
      "loss 0.14856669306755066\n",
      "steps done 1400220\n",
      "1860 episodes completed\n",
      "loss 1.5463426113128662\n",
      "steps done 1404460\n",
      "1865 episodes completed\n",
      "loss 0.00026972286286763847\n",
      "steps done 1408260\n",
      "1870 episodes completed\n",
      "loss 0.0001000503107206896\n",
      "steps done 1411730\n",
      "1875 episodes completed\n",
      "loss 0.00011930412438232452\n",
      "steps done 1415590\n",
      "1880 episodes completed\n",
      "loss 0.9834766387939453\n",
      "steps done 1418710\n",
      "1885 episodes completed\n",
      "loss 0.0003939040470868349\n",
      "steps done 1422730\n",
      "1890 episodes completed\n",
      "loss 2.5522749423980713\n",
      "steps done 1426490\n",
      "1895 episodes completed\n",
      "loss 0.0004012045683339238\n",
      "steps done 1430070\n",
      "1900 episodes completed\n",
      "loss 0.22891536355018616\n",
      "steps done 1433650\n",
      "1905 episodes completed\n",
      "loss 0.009946216829121113\n",
      "steps done 1437470\n",
      "1910 episodes completed\n",
      "loss 3.567693056538701e-05\n",
      "steps done 1441350\n",
      "1915 episodes completed\n",
      "loss 0.04768303781747818\n",
      "steps done 1445100\n",
      "1920 episodes completed\n",
      "loss 5.7424560509389266e-05\n",
      "steps done 1449060\n",
      "1925 episodes completed\n",
      "loss 0.24930119514465332\n",
      "steps done 1452870\n",
      "1930 episodes completed\n",
      "loss 0.8394033908843994\n",
      "steps done 1456660\n",
      "1935 episodes completed\n",
      "loss 0.08194391429424286\n",
      "steps done 1460600\n",
      "1940 episodes completed\n",
      "loss 5.461687032948248e-05\n",
      "steps done 1464120\n",
      "1945 episodes completed\n",
      "loss 6.890091026434675e-05\n",
      "steps done 1467660\n",
      "1950 episodes completed\n",
      "loss 5.790283466922119e-05\n",
      "steps done 1470940\n",
      "1955 episodes completed\n",
      "loss 0.00388923566788435\n",
      "steps done 1474140\n",
      "1960 episodes completed\n",
      "loss 1.265823245048523\n",
      "steps done 1477810\n",
      "1965 episodes completed\n",
      "loss 0.9020217657089233\n",
      "steps done 1481510\n",
      "1970 episodes completed\n",
      "loss 0.00040926208021119237\n",
      "steps done 1484870\n",
      "1975 episodes completed\n",
      "loss 6.0500387917272747e-05\n",
      "steps done 1489060\n",
      "1980 episodes completed\n",
      "loss 0.0001029928753268905\n",
      "steps done 1493110\n",
      "1985 episodes completed\n",
      "loss 0.15044428408145905\n",
      "steps done 1496750\n",
      "1990 episodes completed\n",
      "loss 0.00020882383978459984\n",
      "steps done 1500620\n",
      "1995 episodes completed\n",
      "loss 1.3885319232940674\n",
      "steps done 1504520\n",
      "2000 episodes completed\n",
      "loss 0.0006345695583149791\n",
      "steps done 1508400\n",
      "2005 episodes completed\n",
      "loss 0.6508602499961853\n",
      "steps done 1512090\n",
      "2010 episodes completed\n",
      "loss 0.0004664399311877787\n",
      "steps done 1515610\n",
      "update target\n",
      "update target\n",
      "update target\n",
      "update target\n",
      "update target\n",
      "2015 episodes completed\n",
      "loss 0.000316607765853405\n",
      "steps done 1518640\n",
      "2020 episodes completed\n",
      "loss 0.00016008545935619622\n",
      "steps done 1522790\n",
      "2025 episodes completed\n",
      "loss 0.0001306924386881292\n",
      "steps done 1526480\n",
      "2030 episodes completed\n",
      "loss 0.03340071439743042\n",
      "steps done 1530000\n",
      "2035 episodes completed\n",
      "loss 0.00013800286978948861\n",
      "steps done 1533890\n",
      "2040 episodes completed\n",
      "loss 0.0032510769087821245\n",
      "steps done 1537750\n",
      "2045 episodes completed\n",
      "loss 0.00013823420158587396\n",
      "steps done 1541500\n",
      "2050 episodes completed\n",
      "loss 0.0010550585575401783\n",
      "steps done 1545010\n",
      "2055 episodes completed\n",
      "loss 0.038200799375772476\n",
      "steps done 1549060\n",
      "2060 episodes completed\n",
      "loss 0.36392149329185486\n",
      "steps done 1553100\n",
      "2065 episodes completed\n",
      "loss 0.020069876685738564\n",
      "steps done 1557150\n",
      "2070 episodes completed\n",
      "loss 7.884480874054134e-05\n",
      "steps done 1560960\n",
      "2075 episodes completed\n",
      "loss 0.0002687612141016871\n",
      "steps done 1564800\n",
      "2080 episodes completed\n",
      "loss 0.15885208547115326\n",
      "steps done 1569330\n",
      "2085 episodes completed\n",
      "loss 0.0003882438177242875\n",
      "steps done 1572980\n",
      "2090 episodes completed\n",
      "loss 0.0018045222386717796\n",
      "steps done 1577010\n",
      "2095 episodes completed\n",
      "loss 0.024377239868044853\n",
      "steps done 1581240\n",
      "2100 episodes completed\n",
      "loss 1.02678644657135\n",
      "steps done 1584820\n",
      "2105 episodes completed\n",
      "loss 1.0131691694259644\n",
      "steps done 1587830\n",
      "2110 episodes completed\n",
      "loss 0.05582097917795181\n",
      "steps done 1591420\n",
      "2115 episodes completed\n",
      "loss 0.00018801912665367126\n",
      "steps done 1595640\n",
      "2120 episodes completed\n",
      "loss 6.880266300868243e-05\n",
      "steps done 1599610\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://nsmzse6l4c.clg07azjl.paperspacegradient.com/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "DT          = 0.5  # Time between wildfire updates            \n",
    "DTI         = 0.1  # Time between aircraft decisions\n",
    "fireEnv = ProbabilisticFireEnv(height, width)\n",
    "dronesEnv = DronesEnv(height, width, DT, DTI) \n",
    "loss = None\n",
    "i_episode = 1\n",
    "\n",
    "observation = fireEnv.reset()\n",
    "dronesEnv.reset(observation)\n",
    "\n",
    "episode_memory_1 = []\n",
    "episode_memory_2 = []\n",
    "\n",
    "hidden_1 = policy_net.init_hidden_state()\n",
    "hidden_2 = policy_net.init_hidden_state()\n",
    "\n",
    "while True:\n",
    "  # Initialize the environment and state\n",
    "  #env.reset()\n",
    "  for j in range(TRAIN_FREQ//int(2*DT/DTI)):\n",
    "\n",
    "    observation = fireEnv.step()\n",
    "\n",
    "    state_vector_1 = dronesEnv.drones[0].state\n",
    "    map_1 = dronesEnv.drones[0].observation\n",
    "    state_vector_1 = torch.tensor(state_vector_1, device=device, dtype=torch.float)\n",
    "    map_1 = torch.tensor(map_1, device=device, dtype=torch.float)\n",
    "\n",
    "    state_vector_2 = dronesEnv.drones[1].state\n",
    "    map_2 = dronesEnv.drones[1].observation\n",
    "    state_vector_2 = torch.tensor(state_vector_2, device=device, dtype=torch.float)\n",
    "    map_2 = torch.tensor(map_2, device=device, dtype=torch.float)\n",
    "\n",
    "\n",
    "    for i in range(int(DT/DTI)):\n",
    "\n",
    "      action1, hidden_1 = policy_net.select_action(map_1, state_vector_1, steps, hidden=hidden_1)\n",
    "      action2, hidden_2 = policy_net.select_action(map_2, state_vector_2, steps, hidden=hidden_2)\n",
    "      steps += 2\n",
    "      reward_1, reward_2 = dronesEnv.step([action1.item(), action2.item()], observation)\n",
    "\n",
    "      next_state_vector_1 = dronesEnv.drones[0].state\n",
    "      next_map_1 = dronesEnv.drones[0].observation\n",
    "\n",
    "      next_state_vector_1 = torch.tensor(next_state_vector_1, device=device, dtype=torch.float)\n",
    "      next_map_1 = torch.tensor(next_map_1, device=device, dtype=torch.float)\n",
    "\n",
    "      next_state_vector_2 = dronesEnv.drones[1].state\n",
    "      next_map_2 = dronesEnv.drones[1].observation\n",
    "\n",
    "      next_state_vector_2 = torch.tensor(next_state_vector_2, device=device, dtype=torch.float)\n",
    "      next_map_2 = torch.tensor(next_map_2, device=device, dtype=torch.float)\n",
    "\n",
    "      reward_1 = torch.tensor([reward_1], device=device)\n",
    "      reward_2 = torch.tensor([reward_2], device=device)  \n",
    "\n",
    "      episode_memory_1.append(Transition(map_1, state_vector_1, action1, next_map_1, next_state_vector_1, reward_1))\n",
    "      episode_memory_2.append(Transition(map_2, state_vector_2, action2, next_map_2, next_state_vector_2, reward_2))\n",
    "\n",
    "      state_vector_1 = next_state_vector_1\n",
    "      state_vector_2 = next_state_vector_2\n",
    "\n",
    "      map_1 = next_map_1\n",
    "      map_2 = next_map_2\n",
    "\n",
    "\n",
    "    if not fireEnv.fire_in_range(6):\n",
    "      observation = fireEnv.reset()\n",
    "      dronesEnv.reset(observation)\n",
    "      episode_buffer.push(episode_memory_1.copy())\n",
    "      episode_buffer.push(episode_memory_2.copy())\n",
    "      episode_memory_1 = []\n",
    "      episode_memory_2 = []\n",
    "      hidden_1 = policy_net.init_hidden_state()\n",
    "      hidden_2 = policy_net.init_hidden_state()\n",
    "      i_episode +=1\n",
    "      \n",
    "      if (i_episode+1) % 5 == 0:\n",
    "        print(f'{i_episode+1} episodes completed')\n",
    "        print(f'loss {loss}')\n",
    "        print(f'steps done {steps}')\n",
    "\n",
    "      if i_episode>=INIT_SIZE:\n",
    "        loss = optimize_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
