{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.9/dist-packages (1.6.2)\n",
      "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (1.12.0+cu116)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (1.23.1)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (2.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (1.4.3)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (4.13.0)\n",
      "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (0.21.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable_baselines3) (3.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata~=4.13->stable_baselines3) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable_baselines3) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable_baselines3) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable_baselines3) (4.34.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable_baselines3) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable_baselines3) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->stable_baselines3) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: svgpath2mpl in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (3.5.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (1.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (1.4.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (4.34.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->svgpath2mpl) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.21.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.23.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install stable_baselines3\n",
    "!pip install svgpath2mpl\n",
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from environments.shared_wildfire_gym import SharedWildFireGym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "\n",
    "    def _get_conv_out(self):\n",
    "        o = self.conv(torch.zeros(1, 2, 100, 100))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 4):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "\n",
    "        self.fc1  = nn.Sequential(\n",
    "            nn.Linear(5, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(2, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    \n",
    "        conv_out_size = self._get_conv_out()\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "        nn.Linear(conv_out_size, 500),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(500, 100),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Sequential(nn.Linear(150, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations):\n",
    "        input = torch.cat(\n",
    "            [\n",
    "                observations['bank_angle'], \n",
    "                observations['rho'], observations['theta'], \n",
    "                observations['psi'], \n",
    "                observations['other_bank_angle']\n",
    "            ], dim=1)\n",
    "        fc1_out = self.fc1(input)\n",
    "        conv_out = torch.flatten(self.conv(observations['belief_map']),1)\n",
    "        fc2_out = self.fc2(conv_out)\n",
    "        return self.flatten(torch.cat((fc1_out, fc2_out), dim=1))\n",
    "\n",
    "\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The algorithm only supports (<class 'gym.spaces.box.Box'>, <class 'gym.spaces.discrete.Discrete'>, <class 'gym.spaces.multi_discrete.MultiDiscrete'>, <class 'gym.spaces.multi_binary.MultiBinary'>) as action spaces but Tuple(Discrete(2), Discrete(2)) was provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jeremy/Desktop/projects/notebooks/Distributed Wildfire Surveillance/stable_baseline.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/stable_baseline.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wildFireGym \u001b[39m=\u001b[39m SharedWildFireGym()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/stable_baseline.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m PPO(\u001b[39m\"\u001b[39;49m\u001b[39mCnnPolicy\u001b[39;49m\u001b[39m\"\u001b[39;49m, wildFireGym, verbose\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/stable_baseline.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mlearn(total_timesteps\u001b[39m=\u001b[39m\u001b[39m2000000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/stable_baseline.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mpolicy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/stable_baselines3/ppo/ppo.py:107\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     81\u001b[0m     policy: Union[\u001b[39mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m     _init_setup_model: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    105\u001b[0m ):\n\u001b[0;32m--> 107\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    108\u001b[0m         policy,\n\u001b[1;32m    109\u001b[0m         env,\n\u001b[1;32m    110\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    111\u001b[0m         n_steps\u001b[39m=\u001b[39;49mn_steps,\n\u001b[1;32m    112\u001b[0m         gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    113\u001b[0m         gae_lambda\u001b[39m=\u001b[39;49mgae_lambda,\n\u001b[1;32m    114\u001b[0m         ent_coef\u001b[39m=\u001b[39;49ment_coef,\n\u001b[1;32m    115\u001b[0m         vf_coef\u001b[39m=\u001b[39;49mvf_coef,\n\u001b[1;32m    116\u001b[0m         max_grad_norm\u001b[39m=\u001b[39;49mmax_grad_norm,\n\u001b[1;32m    117\u001b[0m         use_sde\u001b[39m=\u001b[39;49muse_sde,\n\u001b[1;32m    118\u001b[0m         sde_sample_freq\u001b[39m=\u001b[39;49msde_sample_freq,\n\u001b[1;32m    119\u001b[0m         tensorboard_log\u001b[39m=\u001b[39;49mtensorboard_log,\n\u001b[1;32m    120\u001b[0m         policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs,\n\u001b[1;32m    121\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    122\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    123\u001b[0m         create_eval_env\u001b[39m=\u001b[39;49mcreate_eval_env,\n\u001b[1;32m    124\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    125\u001b[0m         _init_setup_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    126\u001b[0m         supported_action_spaces\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    127\u001b[0m             spaces\u001b[39m.\u001b[39;49mBox,\n\u001b[1;32m    128\u001b[0m             spaces\u001b[39m.\u001b[39;49mDiscrete,\n\u001b[1;32m    129\u001b[0m             spaces\u001b[39m.\u001b[39;49mMultiDiscrete,\n\u001b[1;32m    130\u001b[0m             spaces\u001b[39m.\u001b[39;49mMultiBinary,\n\u001b[1;32m    131\u001b[0m         ),\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# because of the advantage normalization\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[39mif\u001b[39;00m normalize_advantage:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/stable_baselines3/common/on_policy_algorithm.py:81\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, tensorboard_log, create_eval_env, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     59\u001b[0m     policy: Union[\u001b[39mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     supported_action_spaces: Optional[Tuple[gym\u001b[39m.\u001b[39mspaces\u001b[39m.\u001b[39mSpace, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     82\u001b[0m         policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[1;32m     83\u001b[0m         env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m     84\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     85\u001b[0m         policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs,\n\u001b[1;32m     86\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     87\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     88\u001b[0m         use_sde\u001b[39m=\u001b[39;49muse_sde,\n\u001b[1;32m     89\u001b[0m         sde_sample_freq\u001b[39m=\u001b[39;49msde_sample_freq,\n\u001b[1;32m     90\u001b[0m         create_eval_env\u001b[39m=\u001b[39;49mcreate_eval_env,\n\u001b[1;32m     91\u001b[0m         support_multi_env\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     92\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m     93\u001b[0m         tensorboard_log\u001b[39m=\u001b[39;49mtensorboard_log,\n\u001b[1;32m     94\u001b[0m         supported_action_spaces\u001b[39m=\u001b[39;49msupported_action_spaces,\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps \u001b[39m=\u001b[39m n_steps\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m=\u001b[39m gamma\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/stable_baselines3/common/base_class.py:187\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, create_eval_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m env\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m supported_action_spaces \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, supported_action_spaces), (\n\u001b[1;32m    188\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe algorithm only supports \u001b[39m\u001b[39m{\u001b[39;00msupported_action_spaces\u001b[39m}\u001b[39;00m\u001b[39m as action spaces \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m}\u001b[39;00m\u001b[39m was provided\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m support_multi_env \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_envs \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    193\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError: the model does not support multiple envs; it requires \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma single vectorized environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: The algorithm only supports (<class 'gym.spaces.box.Box'>, <class 'gym.spaces.discrete.Discrete'>, <class 'gym.spaces.multi_discrete.MultiDiscrete'>, <class 'gym.spaces.multi_binary.MultiBinary'>) as action spaces but Tuple(Discrete(2), Discrete(2)) was provided"
     ]
    }
   ],
   "source": [
    "wildFireGym = SharedWildFireGym()\n",
    "model = PPO(\"MultiInputPolicy\", wildFireGym, verbose=3, n_epochs=5, policy_kwargs=policy_kwargs)\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(\"policy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
