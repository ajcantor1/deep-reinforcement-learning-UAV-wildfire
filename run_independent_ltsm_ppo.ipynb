{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting svgpath2mpl\n",
      "  Downloading svgpath2mpl-1.0.0-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (3.5.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (1.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (4.34.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->svgpath2mpl) (1.14.0)\n",
      "Installing collected packages: svgpath2mpl\n",
      "Successfully installed svgpath2mpl-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install svgpath2mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "from env.wildfire_gym import WildFireGym\n",
    "from networks.lstm_ppo_net import LSTMPPONet\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT          = 0.5  # Time between wildfire updates            \n",
    "DTI         = 0.1  # Time between aircraft decisions\n",
    "n_actions = 2\n",
    "height = width = 100\n",
    "channels = 2\n",
    "EPISODES_PER_BATCH = 1\n",
    "TRAIN_FREQ  = 10\n",
    "SAVE_FREQ = 20\n",
    "GAMMA = 0.95\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "LAMDA = 0.9\n",
    "UPDATES = 10000\n",
    "EPSILON = 0.1\n",
    "\n",
    "EPOCHS = 10\n",
    "NUM_PROCESSES = 1\n",
    "BETA = 0.01\n",
    "TAU = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMPPONet(device,  channels, height, width, n_actions).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('belief_map', 'state_vector', 'action', 'reward', 'value', 'log_policy'))\n",
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "  def __init__(self):\n",
    "    self._memory = []\n",
    "    \n",
    "  def push(self, *args):\n",
    "    \"\"\"Save a transition\"\"\"\n",
    "    self._memory.append(Transition(*args))\n",
    "\n",
    "  @property\n",
    "  def get_batch(self):\n",
    "    return self._memory\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self._memory)\n",
    "\n",
    "  def clear(self):\n",
    "    self._memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT          = 0.5  # Time between wildfire updates            \n",
    "DTI         = 0.1  # Time between aircraft decisions\n",
    "fireEnv = ProbabilisticFireEnv(height, width)\n",
    "dronesEnv = DronesEnv(height, width, DT, DTI) \n",
    "loss = None\n",
    "i_episode = 1\n",
    "SAVE_MODEL = 10\n",
    "N_DRONES = 2\n",
    "steps = 0\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1. Total loss: -0.38577336072921753\n",
      "Episode: 1. Total loss: -0.27506178617477417\n",
      "Episode: 2. Total loss: -0.022573454305529594\n",
      "Episode: 2. Total loss: 0.030814310535788536\n",
      "Episode: 3. Total loss: -0.093963123857975\n",
      "Episode: 3. Total loss: 0.010571378283202648\n",
      "Episode: 4. Total loss: 0.48500415682792664\n",
      "Episode: 4. Total loss: -3.007322311401367\n",
      "Episode: 5. Total loss: -3.2084686756134033\n",
      "Episode: 5. Total loss: 1.6719194650650024\n",
      "Episode: 6. Total loss: -1.0934234857559204\n",
      "Episode: 6. Total loss: -9.371543884277344\n",
      "Episode: 7. Total loss: 0.10459330677986145\n",
      "Episode: 7. Total loss: -7.5029616355896\n",
      "Episode: 8. Total loss: 1.010820746421814\n",
      "Episode: 8. Total loss: 3.2413010597229004\n",
      "Episode: 9. Total loss: -2.3888533115386963\n",
      "Episode: 9. Total loss: -0.8025475740432739\n",
      "saved\n",
      "Episode: 10. Total loss: 3.961761236190796\n",
      "Episode: 10. Total loss: 1.7014371156692505\n",
      "Episode: 11. Total loss: 0.11677248030900955\n",
      "Episode: 11. Total loss: 0.10249751806259155\n",
      "Episode: 12. Total loss: 0.019730446860194206\n",
      "Episode: 12. Total loss: -0.01031140424311161\n",
      "Episode: 13. Total loss: 2.509723663330078\n",
      "Episode: 13. Total loss: 4.491713523864746\n",
      "Episode: 14. Total loss: -0.9186602830886841\n",
      "Episode: 14. Total loss: 0.041162725538015366\n",
      "Episode: 15. Total loss: -6.992803573608398\n",
      "Episode: 15. Total loss: 1.9538381099700928\n",
      "Episode: 16. Total loss: -0.05397558957338333\n",
      "Episode: 16. Total loss: -8.4297513961792\n",
      "Episode: 17. Total loss: 0.889121413230896\n",
      "Episode: 17. Total loss: 6.086820125579834\n",
      "Episode: 18. Total loss: -3.260929584503174\n",
      "Episode: 18. Total loss: -0.39173558354377747\n",
      "Episode: 19. Total loss: 3.696115732192993\n",
      "Episode: 19. Total loss: 17.28360366821289\n",
      "saved\n",
      "Episode: 20. Total loss: -7.0092244148254395\n",
      "Episode: 20. Total loss: -10.813920021057129\n",
      "Episode: 21. Total loss: -3.4124395847320557\n",
      "Episode: 21. Total loss: 15.041873931884766\n",
      "Episode: 22. Total loss: 12.636523246765137\n",
      "Episode: 22. Total loss: 13.231361389160156\n",
      "Episode: 23. Total loss: -3.9392542839050293\n",
      "Episode: 23. Total loss: -7.423239231109619\n",
      "Episode: 24. Total loss: 0.6084294319152832\n",
      "Episode: 24. Total loss: 0.11626864224672318\n",
      "Episode: 25. Total loss: -3.3413705825805664\n",
      "Episode: 25. Total loss: -5.391972064971924\n",
      "Episode: 26. Total loss: 4.454714298248291\n",
      "Episode: 26. Total loss: 0.1747010201215744\n",
      "Episode: 27. Total loss: 6.484282970428467\n",
      "Episode: 27. Total loss: -0.030356846749782562\n",
      "Episode: 28. Total loss: -0.0739365741610527\n",
      "Episode: 28. Total loss: -0.00010468950495123863\n",
      "Episode: 29. Total loss: -6.613626480102539\n",
      "Episode: 29. Total loss: 12.526440620422363\n",
      "saved\n",
      "Episode: 30. Total loss: 0.5838885307312012\n",
      "Episode: 30. Total loss: 0.5618849992752075\n",
      "Episode: 31. Total loss: -4.526637077331543\n",
      "Episode: 31. Total loss: 3.9771220684051514\n",
      "Episode: 32. Total loss: 0.07166208326816559\n",
      "Episode: 32. Total loss: 0.2142704278230667\n",
      "Episode: 33. Total loss: 0.15656931698322296\n",
      "Episode: 33. Total loss: 1.1556307077407837\n",
      "Episode: 34. Total loss: 1.5561596155166626\n",
      "Episode: 34. Total loss: 0.1354518085718155\n",
      "Episode: 35. Total loss: -6.070853233337402\n",
      "Episode: 35. Total loss: 0.05306250974535942\n",
      "Episode: 36. Total loss: -0.9211511015892029\n",
      "Episode: 36. Total loss: 2.168652057647705\n",
      "Episode: 37. Total loss: 0.3744785487651825\n",
      "Episode: 37. Total loss: 1.760053277015686\n",
      "Episode: 38. Total loss: 0.3101264536380768\n",
      "Episode: 38. Total loss: -6.007479667663574\n",
      "Episode: 39. Total loss: 11.284820556640625\n",
      "Episode: 39. Total loss: -7.471907138824463\n",
      "saved\n",
      "Episode: 40. Total loss: -11.83767318725586\n",
      "Episode: 40. Total loss: -1.0534334182739258\n",
      "Episode: 41. Total loss: 0.107564777135849\n",
      "Episode: 41. Total loss: -0.09557551890611649\n",
      "Episode: 42. Total loss: 2.137781858444214\n",
      "Episode: 42. Total loss: -4.970147609710693\n",
      "Episode: 43. Total loss: -5.696732044219971\n",
      "Episode: 43. Total loss: -1.4138890504837036\n",
      "Episode: 44. Total loss: -3.810482978820801\n",
      "Episode: 44. Total loss: -3.4511842727661133\n",
      "Episode: 45. Total loss: 1.0046813488006592\n",
      "Episode: 45. Total loss: -8.179668426513672\n",
      "Episode: 46. Total loss: 0.41862720251083374\n",
      "Episode: 46. Total loss: -4.402696132659912\n",
      "Episode: 47. Total loss: 13.928613662719727\n",
      "Episode: 47. Total loss: -0.7358654141426086\n",
      "Episode: 48. Total loss: 15.956218719482422\n",
      "Episode: 48. Total loss: 19.724618911743164\n",
      "Episode: 49. Total loss: -8.789175987243652\n",
      "Episode: 49. Total loss: -0.8723917603492737\n",
      "saved\n",
      "Episode: 50. Total loss: 0.09732331335544586\n",
      "Episode: 50. Total loss: 8.308389663696289\n",
      "Episode: 51. Total loss: -2.282231092453003\n",
      "Episode: 51. Total loss: 2.143605947494507\n",
      "Episode: 52. Total loss: 0.03132086992263794\n",
      "Episode: 52. Total loss: -6.2944722175598145\n",
      "Episode: 53. Total loss: -0.39957231283187866\n",
      "Episode: 53. Total loss: -0.2093229740858078\n",
      "Episode: 54. Total loss: -6.012809753417969\n",
      "Episode: 54. Total loss: -0.001156806480139494\n",
      "Episode: 55. Total loss: -1.5629453659057617\n",
      "Episode: 55. Total loss: -6.358096122741699\n",
      "Episode: 56. Total loss: -0.3943730592727661\n",
      "Episode: 56. Total loss: 12.375202178955078\n",
      "Episode: 57. Total loss: -0.10991766303777695\n",
      "Episode: 57. Total loss: -0.012942668981850147\n",
      "Episode: 58. Total loss: 3.6142051219940186\n",
      "Episode: 58. Total loss: 0.7644602656364441\n",
      "Episode: 59. Total loss: 0.024821508675813675\n",
      "Episode: 59. Total loss: 30.540388107299805\n",
      "saved\n",
      "Episode: 60. Total loss: 0.5689708590507507\n",
      "Episode: 60. Total loss: -2.4281954765319824\n",
      "Episode: 61. Total loss: 2.4117774963378906\n",
      "Episode: 61. Total loss: 0.3840906023979187\n",
      "Episode: 62. Total loss: -7.506443023681641\n",
      "Episode: 62. Total loss: -0.07830727100372314\n",
      "Episode: 63. Total loss: 0.42507341504096985\n",
      "Episode: 63. Total loss: 5.441205024719238\n",
      "Episode: 64. Total loss: 9.576105117797852\n",
      "Episode: 64. Total loss: 0.6141771674156189\n",
      "Episode: 65. Total loss: 3.5935168266296387\n",
      "Episode: 65. Total loss: -10.115224838256836\n",
      "Episode: 66. Total loss: -4.382980823516846\n",
      "Episode: 66. Total loss: -5.816176414489746\n",
      "Episode: 67. Total loss: 8.861574172973633\n",
      "Episode: 67. Total loss: 10.228458404541016\n",
      "Episode: 68. Total loss: 6.760923385620117\n",
      "Episode: 68. Total loss: 0.42928585410118103\n",
      "Episode: 69. Total loss: 0.2592483162879944\n",
      "Episode: 69. Total loss: 0.4035390317440033\n",
      "saved\n",
      "Episode: 70. Total loss: -0.9517191648483276\n",
      "Episode: 70. Total loss: 0.5329908132553101\n",
      "Episode: 71. Total loss: -0.05499760061502457\n",
      "Episode: 71. Total loss: 0.145982563495636\n",
      "Episode: 72. Total loss: -0.00739090982824564\n",
      "Episode: 72. Total loss: 0.0099254809319973\n",
      "Episode: 73. Total loss: 0.693160355091095\n",
      "Episode: 73. Total loss: -11.609068870544434\n",
      "Episode: 74. Total loss: 2.5047078132629395\n",
      "Episode: 74. Total loss: 0.4071168303489685\n",
      "Episode: 75. Total loss: -10.537023544311523\n",
      "Episode: 75. Total loss: -0.9160178899765015\n",
      "Episode: 76. Total loss: 0.26617589592933655\n",
      "Episode: 76. Total loss: 0.1625639796257019\n",
      "Episode: 77. Total loss: -2.605901002883911\n",
      "Episode: 77. Total loss: 0.8919208645820618\n",
      "Episode: 78. Total loss: 6.748363971710205\n",
      "Episode: 78. Total loss: -0.07357244938611984\n",
      "Episode: 79. Total loss: 0.1789764165878296\n",
      "Episode: 79. Total loss: 0.14878903329372406\n",
      "saved\n",
      "Episode: 80. Total loss: -12.66227912902832\n",
      "Episode: 80. Total loss: -2.698073625564575\n",
      "Episode: 81. Total loss: -14.113082885742188\n",
      "Episode: 81. Total loss: 6.95793342590332\n",
      "Episode: 82. Total loss: 7.141870498657227\n",
      "Episode: 82. Total loss: 1.074021816253662\n",
      "Episode: 83. Total loss: -0.18945501744747162\n",
      "Episode: 83. Total loss: 5.129728317260742\n",
      "Episode: 84. Total loss: -0.7330908179283142\n",
      "Episode: 84. Total loss: 2.6689131259918213\n",
      "Episode: 85. Total loss: 0.30222412943840027\n",
      "Episode: 85. Total loss: 10.598672866821289\n",
      "Episode: 86. Total loss: -0.2882574200630188\n",
      "Episode: 86. Total loss: -7.250017166137695\n",
      "Episode: 87. Total loss: -2.2546939849853516\n",
      "Episode: 87. Total loss: -1.6869006156921387\n",
      "Episode: 88. Total loss: 0.0005708914250135422\n",
      "Episode: 88. Total loss: 0.18624775111675262\n",
      "Episode: 89. Total loss: 13.154325485229492\n",
      "Episode: 89. Total loss: 2.060180902481079\n",
      "saved\n",
      "Episode: 90. Total loss: 15.796067237854004\n",
      "Episode: 90. Total loss: -9.355292320251465\n",
      "Episode: 91. Total loss: 7.719297885894775\n",
      "Episode: 91. Total loss: 20.154560089111328\n",
      "Episode: 92. Total loss: 7.607295036315918\n",
      "Episode: 92. Total loss: 0.060693591833114624\n",
      "Episode: 93. Total loss: 0.37588968873023987\n",
      "Episode: 93. Total loss: 1.8557894229888916\n",
      "Episode: 94. Total loss: 15.733447074890137\n",
      "Episode: 94. Total loss: 2.130869150161743\n",
      "Episode: 95. Total loss: -0.03710106387734413\n",
      "Episode: 95. Total loss: 3.0324759483337402\n",
      "Episode: 96. Total loss: 3.9321179389953613\n",
      "Episode: 96. Total loss: -12.000398635864258\n",
      "Episode: 97. Total loss: -0.3318282961845398\n",
      "Episode: 97. Total loss: 28.899749755859375\n",
      "Episode: 98. Total loss: -1.8175040483474731\n",
      "Episode: 98. Total loss: 1.882497787475586\n",
      "Episode: 99. Total loss: 3.70631742477417\n",
      "Episode: 99. Total loss: 7.525824069976807\n",
      "saved\n",
      "Episode: 100. Total loss: 0.4818183481693268\n",
      "Episode: 100. Total loss: -9.422209739685059\n",
      "Episode: 101. Total loss: 17.7066650390625\n",
      "Episode: 101. Total loss: 1.4981637001037598\n",
      "Episode: 102. Total loss: 0.3685418963432312\n",
      "Episode: 102. Total loss: 22.006031036376953\n",
      "Episode: 103. Total loss: -5.727140426635742\n",
      "Episode: 103. Total loss: 6.906527519226074\n",
      "Episode: 104. Total loss: -6.5693182945251465\n",
      "Episode: 104. Total loss: 15.362327575683594\n",
      "Episode: 105. Total loss: -1.373437762260437\n",
      "Episode: 105. Total loss: 0.09516766667366028\n",
      "Episode: 106. Total loss: 9.172196388244629\n",
      "Episode: 106. Total loss: 6.283956527709961\n",
      "Episode: 107. Total loss: 0.663777232170105\n",
      "Episode: 107. Total loss: 0.479571670293808\n",
      "Episode: 108. Total loss: -0.0898011177778244\n",
      "Episode: 108. Total loss: 0.5281456708908081\n",
      "Episode: 109. Total loss: -5.380392074584961\n",
      "Episode: 109. Total loss: -7.502351760864258\n",
      "saved\n",
      "Episode: 110. Total loss: -2.057276487350464\n",
      "Episode: 110. Total loss: 17.254621505737305\n",
      "Episode: 111. Total loss: -0.20854687690734863\n",
      "Episode: 111. Total loss: 15.041443824768066\n",
      "Episode: 112. Total loss: -0.4649540185928345\n",
      "Episode: 112. Total loss: 8.037823677062988\n",
      "Episode: 113. Total loss: -2.5927493572235107\n",
      "Episode: 113. Total loss: 3.8926661014556885\n",
      "Episode: 114. Total loss: 9.475854873657227\n",
      "Episode: 114. Total loss: -2.9911038875579834\n",
      "Episode: 115. Total loss: -6.634145259857178\n",
      "Episode: 115. Total loss: 1.850131869316101\n",
      "Episode: 116. Total loss: 1.6182340383529663\n",
      "Episode: 116. Total loss: 1.2244868278503418\n",
      "Episode: 117. Total loss: 0.7512809038162231\n",
      "Episode: 117. Total loss: -3.406237840652466\n",
      "Episode: 118. Total loss: 10.951947212219238\n",
      "Episode: 118. Total loss: 4.820961952209473\n",
      "Episode: 119. Total loss: 10.295722007751465\n",
      "Episode: 119. Total loss: 0.0901777520775795\n",
      "saved\n",
      "Episode: 120. Total loss: 0.9017540216445923\n",
      "Episode: 120. Total loss: 9.472498893737793\n",
      "Episode: 121. Total loss: 10.651928901672363\n",
      "Episode: 121. Total loss: 1.8351589441299438\n",
      "Episode: 122. Total loss: 0.01246030442416668\n",
      "Episode: 122. Total loss: 2.108224868774414\n",
      "Episode: 123. Total loss: 0.003335006069391966\n",
      "Episode: 123. Total loss: -0.06413017958402634\n",
      "Episode: 124. Total loss: -2.4787895679473877\n",
      "Episode: 124. Total loss: -6.124134063720703\n",
      "Episode: 125. Total loss: -0.09360907226800919\n",
      "Episode: 125. Total loss: -0.09198177605867386\n",
      "Episode: 126. Total loss: 18.92357063293457\n",
      "Episode: 126. Total loss: -4.294190883636475\n",
      "Episode: 127. Total loss: 0.37714797258377075\n",
      "Episode: 127. Total loss: 0.11538484692573547\n",
      "Episode: 128. Total loss: -0.020405907183885574\n",
      "Episode: 128. Total loss: 0.017260223627090454\n",
      "Episode: 129. Total loss: 14.670661926269531\n",
      "Episode: 129. Total loss: 2.9001922607421875\n",
      "saved\n",
      "Episode: 130. Total loss: -0.07255859673023224\n",
      "Episode: 130. Total loss: 23.179731369018555\n",
      "Episode: 131. Total loss: -6.2019500732421875\n",
      "Episode: 131. Total loss: -7.562407970428467\n",
      "Episode: 132. Total loss: 0.0440276600420475\n",
      "Episode: 132. Total loss: -0.03747297450900078\n",
      "Episode: 133. Total loss: -0.3858982026576996\n",
      "Episode: 133. Total loss: -1.6799836158752441\n",
      "Episode: 134. Total loss: 3.5926928520202637\n",
      "Episode: 134. Total loss: 0.8500099182128906\n",
      "Episode: 135. Total loss: 5.820882320404053\n",
      "Episode: 135. Total loss: 6.191585063934326\n",
      "Episode: 136. Total loss: 17.053335189819336\n",
      "Episode: 136. Total loss: 39.49946212768555\n",
      "Episode: 137. Total loss: -4.84906005859375\n",
      "Episode: 137. Total loss: 0.19132159650325775\n",
      "Episode: 138. Total loss: -9.090927124023438\n",
      "Episode: 138. Total loss: -0.7843194007873535\n",
      "Episode: 139. Total loss: 10.229357719421387\n",
      "Episode: 139. Total loss: 1.037872552871704\n",
      "saved\n",
      "Episode: 140. Total loss: 0.08592642098665237\n",
      "Episode: 140. Total loss: -1.8635379076004028\n",
      "Episode: 141. Total loss: -0.7568550109863281\n",
      "Episode: 141. Total loss: 1.1604115962982178\n",
      "Episode: 142. Total loss: 0.05597437545657158\n",
      "Episode: 142. Total loss: 0.39883938431739807\n",
      "Episode: 143. Total loss: 6.696384906768799\n",
      "Episode: 143. Total loss: 3.172494649887085\n",
      "Episode: 144. Total loss: 1.4091248512268066\n",
      "Episode: 144. Total loss: -3.8121352195739746\n",
      "Episode: 145. Total loss: 1.0132498741149902\n",
      "Episode: 145. Total loss: 10.953638076782227\n",
      "Episode: 146. Total loss: 6.206686973571777\n",
      "Episode: 146. Total loss: -6.0582451820373535\n",
      "Episode: 147. Total loss: -0.02940778248012066\n",
      "Episode: 147. Total loss: 1.163276195526123\n",
      "Episode: 148. Total loss: 0.02882165089249611\n",
      "Episode: 148. Total loss: -12.44810676574707\n",
      "Episode: 149. Total loss: -4.34649133682251\n",
      "Episode: 149. Total loss: -2.6409924030303955\n",
      "saved\n",
      "Episode: 150. Total loss: -4.619606971740723\n",
      "Episode: 150. Total loss: 1.169357419013977\n",
      "Episode: 151. Total loss: 0.04870648682117462\n",
      "Episode: 151. Total loss: 0.14264151453971863\n",
      "Episode: 152. Total loss: -5.5841264724731445\n",
      "Episode: 152. Total loss: -5.901975154876709\n",
      "Episode: 153. Total loss: -0.7694858908653259\n",
      "Episode: 153. Total loss: -1.259157657623291\n",
      "Episode: 154. Total loss: 43.64603042602539\n",
      "Episode: 154. Total loss: 0.12184859067201614\n",
      "Episode: 155. Total loss: 7.239816188812256\n",
      "Episode: 155. Total loss: -0.0636945366859436\n",
      "Episode: 156. Total loss: 26.347700119018555\n",
      "Episode: 156. Total loss: 22.29677963256836\n",
      "Episode: 157. Total loss: -3.9828755855560303\n",
      "Episode: 157. Total loss: 13.348637580871582\n",
      "Episode: 158. Total loss: 31.858015060424805\n",
      "Episode: 158. Total loss: 24.785280227661133\n",
      "Episode: 159. Total loss: 60.04793167114258\n",
      "Episode: 159. Total loss: 21.140047073364258\n",
      "saved\n",
      "Episode: 160. Total loss: 9.477673530578613\n",
      "Episode: 160. Total loss: 3.5313360691070557\n",
      "Episode: 161. Total loss: 31.419265747070312\n",
      "Episode: 161. Total loss: 11.851691246032715\n",
      "Episode: 162. Total loss: 4.767690181732178\n",
      "Episode: 162. Total loss: 11.83336353302002\n",
      "Episode: 163. Total loss: 0.11107609421014786\n",
      "Episode: 163. Total loss: -2.7801578044891357\n",
      "Episode: 164. Total loss: -5.4833831787109375\n",
      "Episode: 164. Total loss: 1.035715937614441\n",
      "Episode: 165. Total loss: 5.428325176239014\n",
      "Episode: 165. Total loss: 25.60909652709961\n",
      "Episode: 166. Total loss: 6.972156047821045\n",
      "Episode: 166. Total loss: 42.354305267333984\n",
      "Episode: 167. Total loss: 26.502729415893555\n",
      "Episode: 167. Total loss: 24.094833374023438\n",
      "Episode: 168. Total loss: 3.952425718307495\n",
      "Episode: 168. Total loss: -2.1022846698760986\n",
      "Episode: 169. Total loss: 3.5001657009124756\n",
      "Episode: 169. Total loss: 9.103601455688477\n",
      "saved\n",
      "Episode: 170. Total loss: -7.243756294250488\n",
      "Episode: 170. Total loss: -2.5747833251953125\n",
      "Episode: 171. Total loss: 7.48335075378418\n",
      "Episode: 171. Total loss: 8.063886642456055\n",
      "Episode: 172. Total loss: 5.2241435050964355\n",
      "Episode: 172. Total loss: -1.2361823320388794\n",
      "Episode: 173. Total loss: -9.012752532958984\n",
      "Episode: 173. Total loss: 0.11731289327144623\n",
      "Episode: 174. Total loss: -4.474964618682861\n",
      "Episode: 174. Total loss: 0.5548365116119385\n",
      "Episode: 175. Total loss: 0.023512553423643112\n",
      "Episode: 175. Total loss: 0.013216190040111542\n",
      "Episode: 176. Total loss: 9.304869651794434\n",
      "Episode: 176. Total loss: 2.5920639038085938\n",
      "Episode: 177. Total loss: 5.444602012634277\n",
      "Episode: 177. Total loss: 8.362875938415527\n",
      "Episode: 178. Total loss: 5.656954288482666\n",
      "Episode: 178. Total loss: -8.422752380371094\n",
      "Episode: 179. Total loss: 3.633906364440918\n",
      "Episode: 179. Total loss: 5.603837013244629\n",
      "saved\n",
      "Episode: 180. Total loss: 15.442671775817871\n",
      "Episode: 180. Total loss: 5.872368335723877\n",
      "Episode: 181. Total loss: 5.865926265716553\n",
      "Episode: 181. Total loss: 8.221631050109863\n",
      "Episode: 182. Total loss: 1.1323779821395874\n",
      "Episode: 182. Total loss: 7.867071151733398\n",
      "Episode: 183. Total loss: 12.346242904663086\n",
      "Episode: 183. Total loss: 12.359137535095215\n",
      "Episode: 184. Total loss: 6.336418151855469\n",
      "Episode: 184. Total loss: -7.886491775512695\n",
      "Episode: 185. Total loss: -1.8457694053649902\n",
      "Episode: 185. Total loss: -5.05063533782959\n",
      "Episode: 186. Total loss: 5.060108184814453\n",
      "Episode: 186. Total loss: 34.70270919799805\n",
      "Episode: 187. Total loss: -1.6884617805480957\n",
      "Episode: 187. Total loss: -2.5485754013061523\n",
      "Episode: 188. Total loss: 13.907137870788574\n",
      "Episode: 188. Total loss: 1.1875239610671997\n",
      "Episode: 189. Total loss: -0.9907016754150391\n",
      "Episode: 189. Total loss: 1.4283549785614014\n",
      "saved\n",
      "Episode: 190. Total loss: 20.506553649902344\n",
      "Episode: 190. Total loss: 1.9575965404510498\n",
      "Episode: 191. Total loss: 13.351799964904785\n",
      "Episode: 191. Total loss: -11.683415412902832\n",
      "Episode: 192. Total loss: 11.348407745361328\n",
      "Episode: 192. Total loss: 12.163789749145508\n",
      "Episode: 193. Total loss: 0.08714979141950607\n",
      "Episode: 193. Total loss: 0.08667977154254913\n",
      "Episode: 194. Total loss: 5.033379554748535\n",
      "Episode: 194. Total loss: 25.18193817138672\n",
      "Episode: 195. Total loss: 18.60988998413086\n",
      "Episode: 195. Total loss: 0.39931342005729675\n",
      "Episode: 196. Total loss: -0.008438986726105213\n",
      "Episode: 196. Total loss: 0.06005062907934189\n",
      "Episode: 197. Total loss: 0.04667544737458229\n",
      "Episode: 197. Total loss: 7.292541980743408\n",
      "Episode: 198. Total loss: -11.87158489227295\n",
      "Episode: 198. Total loss: -8.015862464904785\n",
      "Episode: 199. Total loss: 0.020854368805885315\n",
      "Episode: 199. Total loss: -10.288358688354492\n",
      "saved\n",
      "Episode: 200. Total loss: 3.372375726699829\n",
      "Episode: 200. Total loss: 22.6170711517334\n",
      "Episode: 201. Total loss: -6.8132171630859375\n",
      "Episode: 201. Total loss: 0.06160893663764\n",
      "Episode: 202. Total loss: 7.555842399597168\n",
      "Episode: 202. Total loss: 18.30032730102539\n",
      "Episode: 203. Total loss: 1.032912254333496\n",
      "Episode: 203. Total loss: -1.7466055154800415\n",
      "Episode: 204. Total loss: 41.650856018066406\n",
      "Episode: 204. Total loss: 7.049854755401611\n",
      "Episode: 205. Total loss: 15.891364097595215\n",
      "Episode: 205. Total loss: 22.38979721069336\n",
      "Episode: 206. Total loss: 8.15869140625\n",
      "Episode: 206. Total loss: 2.0473194122314453\n",
      "Episode: 207. Total loss: 0.4313822090625763\n",
      "Episode: 207. Total loss: 14.525123596191406\n",
      "Episode: 208. Total loss: -1.624681830406189\n",
      "Episode: 208. Total loss: 10.2706937789917\n",
      "Episode: 209. Total loss: -6.265538215637207\n",
      "Episode: 209. Total loss: 0.050089843571186066\n",
      "saved\n",
      "Episode: 210. Total loss: 5.0214009284973145\n",
      "Episode: 210. Total loss: -0.4620106518268585\n",
      "Episode: 211. Total loss: -36.101806640625\n",
      "Episode: 211. Total loss: 0.1367354393005371\n",
      "Episode: 212. Total loss: 1.0770244598388672\n",
      "Episode: 212. Total loss: 9.305791854858398\n",
      "Episode: 213. Total loss: 18.530193328857422\n",
      "Episode: 213. Total loss: 0.2158973067998886\n",
      "Episode: 214. Total loss: -9.5655517578125\n",
      "Episode: 214. Total loss: 0.907817542552948\n",
      "Episode: 215. Total loss: 15.287069320678711\n",
      "Episode: 215. Total loss: -6.374440670013428\n",
      "Episode: 216. Total loss: 6.803748607635498\n",
      "Episode: 216. Total loss: -13.914304733276367\n",
      "Episode: 217. Total loss: 4.559657573699951\n",
      "Episode: 217. Total loss: 2.1251420974731445\n",
      "Episode: 218. Total loss: -22.856237411499023\n",
      "Episode: 218. Total loss: 0.2811562418937683\n",
      "Episode: 219. Total loss: -5.810815334320068\n",
      "Episode: 219. Total loss: 33.96123504638672\n",
      "saved\n",
      "Episode: 220. Total loss: 10.465911865234375\n",
      "Episode: 220. Total loss: 0.01333616767078638\n",
      "Episode: 221. Total loss: -5.8869781494140625\n",
      "Episode: 221. Total loss: 23.4833927154541\n",
      "Episode: 222. Total loss: -8.952759742736816\n",
      "Episode: 222. Total loss: 17.423830032348633\n",
      "Episode: 223. Total loss: 0.058754317462444305\n",
      "Episode: 223. Total loss: 32.507049560546875\n",
      "Episode: 224. Total loss: -1.6017807722091675\n",
      "Episode: 224. Total loss: 5.800140380859375\n",
      "Episode: 225. Total loss: 8.18818473815918\n",
      "Episode: 225. Total loss: 2.2905566692352295\n",
      "Episode: 226. Total loss: -13.967421531677246\n",
      "Episode: 226. Total loss: 0.0246998630464077\n",
      "Episode: 227. Total loss: 22.2628116607666\n",
      "Episode: 227. Total loss: 15.127554893493652\n",
      "Episode: 228. Total loss: 6.4655351638793945\n",
      "Episode: 228. Total loss: -0.031093062832951546\n",
      "Episode: 229. Total loss: -4.087821960449219\n",
      "Episode: 229. Total loss: -3.08339786529541\n",
      "saved\n",
      "Episode: 230. Total loss: 56.765228271484375\n",
      "Episode: 230. Total loss: -1.05977201461792\n",
      "Episode: 231. Total loss: 7.621916770935059\n",
      "Episode: 231. Total loss: 0.25558871030807495\n",
      "Episode: 232. Total loss: 14.030494689941406\n",
      "Episode: 232. Total loss: 13.233939170837402\n",
      "Episode: 233. Total loss: 24.2110538482666\n",
      "Episode: 233. Total loss: 23.29925537109375\n",
      "Episode: 234. Total loss: 6.4251322746276855\n",
      "Episode: 234. Total loss: 11.59854793548584\n",
      "Episode: 235. Total loss: -0.03291855379939079\n",
      "Episode: 235. Total loss: 11.929423332214355\n",
      "Episode: 236. Total loss: 26.160972595214844\n",
      "Episode: 236. Total loss: 25.872039794921875\n",
      "Episode: 237. Total loss: 0.16792137920856476\n",
      "Episode: 237. Total loss: -2.987715244293213\n",
      "Episode: 238. Total loss: 1.7759473323822021\n",
      "Episode: 238. Total loss: -3.3878262042999268\n",
      "Episode: 239. Total loss: -6.640155792236328\n",
      "Episode: 239. Total loss: 4.617187976837158\n",
      "saved\n",
      "Episode: 240. Total loss: 18.469385147094727\n",
      "Episode: 240. Total loss: 0.2505491077899933\n",
      "Episode: 241. Total loss: 0.04129399359226227\n",
      "Episode: 241. Total loss: 1.3574289083480835\n",
      "Episode: 242. Total loss: 3.7238709926605225\n",
      "Episode: 242. Total loss: 0.05979544669389725\n",
      "Episode: 243. Total loss: -13.050896644592285\n",
      "Episode: 243. Total loss: -0.3540146052837372\n",
      "Episode: 244. Total loss: 0.14824028313159943\n",
      "Episode: 244. Total loss: 0.11101479083299637\n",
      "Episode: 245. Total loss: 0.047542013227939606\n",
      "Episode: 245. Total loss: 22.206777572631836\n",
      "Episode: 246. Total loss: -0.5396144986152649\n",
      "Episode: 246. Total loss: -5.782993793487549\n",
      "Episode: 247. Total loss: -0.04393456503748894\n",
      "Episode: 247. Total loss: -0.03514675050973892\n",
      "Episode: 248. Total loss: 0.024518372491002083\n",
      "Episode: 248. Total loss: 10.49443531036377\n",
      "Episode: 249. Total loss: -0.01942843198776245\n",
      "Episode: 249. Total loss: -0.017102021723985672\n",
      "saved\n",
      "Episode: 250. Total loss: -14.93140983581543\n",
      "Episode: 250. Total loss: 18.92091178894043\n",
      "Episode: 251. Total loss: -0.08015693724155426\n",
      "Episode: 251. Total loss: 13.711481094360352\n",
      "Episode: 252. Total loss: 0.9794154763221741\n",
      "Episode: 252. Total loss: 11.838434219360352\n",
      "Episode: 253. Total loss: 7.353261947631836\n",
      "Episode: 253. Total loss: 15.04888916015625\n",
      "Episode: 254. Total loss: -11.758782386779785\n",
      "Episode: 254. Total loss: -0.027747316285967827\n",
      "Episode: 255. Total loss: 0.7169254422187805\n",
      "Episode: 255. Total loss: -15.209148406982422\n",
      "Episode: 256. Total loss: 28.769920349121094\n",
      "Episode: 256. Total loss: 0.015294133685529232\n",
      "Episode: 257. Total loss: -1.916367530822754\n",
      "Episode: 257. Total loss: 0.07552237808704376\n",
      "Episode: 258. Total loss: -8.372970581054688\n",
      "Episode: 258. Total loss: -0.029769252985715866\n",
      "Episode: 259. Total loss: 0.6538216471672058\n",
      "Episode: 259. Total loss: 5.548710823059082\n",
      "saved\n",
      "Episode: 260. Total loss: 25.500164031982422\n",
      "Episode: 260. Total loss: 0.2235918492078781\n",
      "Episode: 261. Total loss: -4.824246406555176\n",
      "Episode: 261. Total loss: 0.03035055659711361\n",
      "Episode: 262. Total loss: 25.04198455810547\n",
      "Episode: 262. Total loss: 25.282705307006836\n",
      "Episode: 263. Total loss: 26.300168991088867\n",
      "Episode: 263. Total loss: 0.01669963076710701\n",
      "Episode: 264. Total loss: -7.005993843078613\n",
      "Episode: 264. Total loss: -0.04146283119916916\n",
      "Episode: 265. Total loss: 23.531448364257812\n",
      "Episode: 265. Total loss: 2.8882498741149902\n",
      "Episode: 266. Total loss: -0.034251868724823\n",
      "Episode: 266. Total loss: 9.554478645324707\n",
      "Episode: 267. Total loss: 10.3551025390625\n",
      "Episode: 267. Total loss: 17.62248420715332\n",
      "Episode: 268. Total loss: 4.676419734954834\n",
      "Episode: 268. Total loss: 14.420425415039062\n",
      "Episode: 269. Total loss: 17.789203643798828\n",
      "Episode: 269. Total loss: 11.496211051940918\n",
      "saved\n",
      "Episode: 270. Total loss: -17.002897262573242\n",
      "Episode: 270. Total loss: 0.0631634071469307\n",
      "Episode: 271. Total loss: 10.565068244934082\n",
      "Episode: 271. Total loss: 16.650707244873047\n",
      "Episode: 272. Total loss: -1.4422481060028076\n",
      "Episode: 272. Total loss: -4.749157428741455\n",
      "Episode: 273. Total loss: -2.1131412982940674\n",
      "Episode: 273. Total loss: 18.141311645507812\n",
      "Episode: 274. Total loss: 7.999173641204834\n",
      "Episode: 274. Total loss: 29.57012939453125\n",
      "Episode: 275. Total loss: 2.143141031265259\n",
      "Episode: 275. Total loss: 4.612369060516357\n",
      "Episode: 276. Total loss: 1.7209357023239136\n",
      "Episode: 276. Total loss: -5.947422981262207\n",
      "Episode: 277. Total loss: 9.670002937316895\n",
      "Episode: 277. Total loss: 0.28398561477661133\n",
      "Episode: 278. Total loss: -0.04237750172615051\n",
      "Episode: 278. Total loss: -7.590707302093506\n",
      "Episode: 279. Total loss: 1.606860637664795\n",
      "Episode: 279. Total loss: 2.772782325744629\n",
      "saved\n",
      "Episode: 280. Total loss: 22.798723220825195\n",
      "Episode: 280. Total loss: 5.637484073638916\n",
      "Episode: 281. Total loss: 2.0571515560150146\n",
      "Episode: 281. Total loss: 8.900436401367188\n",
      "Episode: 282. Total loss: 23.013046264648438\n",
      "Episode: 282. Total loss: 13.213061332702637\n",
      "Episode: 283. Total loss: -7.0155253410339355\n",
      "Episode: 283. Total loss: 37.30316925048828\n",
      "Episode: 284. Total loss: 8.089789390563965\n",
      "Episode: 284. Total loss: 0.2028009295463562\n",
      "Episode: 285. Total loss: 14.949825286865234\n",
      "Episode: 285. Total loss: 13.25991439819336\n",
      "Episode: 286. Total loss: 13.42628002166748\n",
      "Episode: 286. Total loss: 0.8289246559143066\n",
      "Episode: 287. Total loss: 0.038980383425951004\n",
      "Episode: 287. Total loss: -0.0625872015953064\n",
      "Episode: 288. Total loss: -0.014883629977703094\n",
      "Episode: 288. Total loss: -9.750385284423828\n",
      "Episode: 289. Total loss: 19.721128463745117\n",
      "Episode: 289. Total loss: 0.07493093609809875\n",
      "saved\n",
      "Episode: 290. Total loss: 0.004061515908688307\n",
      "Episode: 290. Total loss: -6.904680252075195\n",
      "Episode: 291. Total loss: -10.23550796508789\n",
      "Episode: 291. Total loss: -1.1142717599868774\n",
      "Episode: 292. Total loss: -4.428638458251953\n",
      "Episode: 292. Total loss: 20.018178939819336\n",
      "Episode: 293. Total loss: -3.9476659297943115\n",
      "Episode: 293. Total loss: 13.175251960754395\n",
      "Episode: 294. Total loss: 0.17654117941856384\n",
      "Episode: 294. Total loss: 0.1612905114889145\n",
      "Episode: 295. Total loss: -3.287806987762451\n",
      "Episode: 295. Total loss: 11.76562213897705\n",
      "Episode: 296. Total loss: 10.76579475402832\n",
      "Episode: 296. Total loss: -14.046756744384766\n",
      "Episode: 297. Total loss: -7.99656867980957\n",
      "Episode: 297. Total loss: 21.693706512451172\n",
      "Episode: 298. Total loss: 30.961881637573242\n",
      "Episode: 298. Total loss: 11.086141586303711\n",
      "Episode: 299. Total loss: 1.3362655639648438\n",
      "Episode: 299. Total loss: 0.06825006008148193\n",
      "saved\n",
      "Episode: 300. Total loss: -15.268013000488281\n",
      "Episode: 300. Total loss: -0.06510090082883835\n",
      "Episode: 301. Total loss: 5.115952014923096\n",
      "Episode: 301. Total loss: 32.91343688964844\n",
      "Episode: 302. Total loss: -4.909963607788086\n",
      "Episode: 302. Total loss: 24.632469177246094\n",
      "Episode: 303. Total loss: 11.201896667480469\n",
      "Episode: 303. Total loss: 9.655898094177246\n",
      "Episode: 304. Total loss: 0.9694917798042297\n",
      "Episode: 304. Total loss: 20.369081497192383\n",
      "Episode: 305. Total loss: -10.219451904296875\n",
      "Episode: 305. Total loss: 0.5942528247833252\n",
      "Episode: 306. Total loss: 19.741851806640625\n",
      "Episode: 306. Total loss: -10.829181671142578\n",
      "Episode: 307. Total loss: 6.5956950187683105\n",
      "Episode: 307. Total loss: 0.040383536368608475\n",
      "Episode: 308. Total loss: 0.11740030348300934\n",
      "Episode: 308. Total loss: -3.385915994644165\n",
      "Episode: 309. Total loss: 6.242954730987549\n",
      "Episode: 309. Total loss: 33.710453033447266\n",
      "saved\n",
      "Episode: 310. Total loss: 12.37979507446289\n",
      "Episode: 310. Total loss: 4.507210731506348\n",
      "Episode: 311. Total loss: 0.8431957960128784\n",
      "Episode: 311. Total loss: 5.286283493041992\n",
      "Episode: 312. Total loss: 0.1555739790201187\n",
      "Episode: 312. Total loss: -7.450445652008057\n",
      "Episode: 313. Total loss: 0.01661878637969494\n",
      "Episode: 313. Total loss: -2.2150561809539795\n",
      "Episode: 314. Total loss: 43.33721923828125\n",
      "Episode: 314. Total loss: 25.740249633789062\n",
      "Episode: 315. Total loss: 12.438841819763184\n",
      "Episode: 315. Total loss: -0.04170622676610947\n",
      "Episode: 316. Total loss: 31.174823760986328\n",
      "Episode: 316. Total loss: 14.38575267791748\n",
      "Episode: 317. Total loss: 33.96284866333008\n",
      "Episode: 317. Total loss: 21.626667022705078\n",
      "Episode: 318. Total loss: 15.199036598205566\n",
      "Episode: 318. Total loss: 12.581806182861328\n",
      "Episode: 319. Total loss: 18.345661163330078\n",
      "Episode: 319. Total loss: 9.420448303222656\n",
      "saved\n",
      "Episode: 320. Total loss: 0.2985946536064148\n",
      "Episode: 320. Total loss: -5.406501293182373\n",
      "Episode: 321. Total loss: 0.005095752887427807\n",
      "Episode: 321. Total loss: -13.127504348754883\n",
      "Episode: 322. Total loss: 2.575187921524048\n",
      "Episode: 322. Total loss: 0.9137136936187744\n",
      "Episode: 323. Total loss: 0.045724302530288696\n",
      "Episode: 323. Total loss: 0.6065975427627563\n",
      "Episode: 324. Total loss: 0.12877905368804932\n",
      "Episode: 324. Total loss: -0.031085168942809105\n",
      "Episode: 325. Total loss: 0.003682633861899376\n",
      "Episode: 325. Total loss: 0.5643346905708313\n",
      "Episode: 326. Total loss: -0.011526016518473625\n",
      "Episode: 326. Total loss: -20.563159942626953\n",
      "Episode: 327. Total loss: 14.732441902160645\n",
      "Episode: 327. Total loss: 7.62922477722168\n",
      "Episode: 328. Total loss: 17.869781494140625\n",
      "Episode: 328. Total loss: 0.24388088285923004\n",
      "Episode: 329. Total loss: -0.05073032155632973\n",
      "Episode: 329. Total loss: 44.305965423583984\n",
      "saved\n",
      "Episode: 330. Total loss: -3.8766510486602783\n",
      "Episode: 330. Total loss: 0.058257900178432465\n",
      "Episode: 331. Total loss: 0.10948502272367477\n",
      "Episode: 331. Total loss: 0.03867229446768761\n",
      "Episode: 332. Total loss: 0.025283604860305786\n",
      "Episode: 332. Total loss: -0.017705848440527916\n",
      "Episode: 333. Total loss: 16.003440856933594\n",
      "Episode: 333. Total loss: -0.07594386488199234\n"
     ]
    }
   ],
   "source": [
    "seed = fireEnv.reset()\n",
    "dronesEnv.reset(seed)\n",
    "\n",
    "memory = [ReplayMemory(), ReplayMemory()]\n",
    "state_vectors = [None]*N_DRONES\n",
    "hidden = [None]*N_DRONES\n",
    "maps = [None]*N_DRONES\n",
    "steps_for_episode = 0 \n",
    "\n",
    "while True:\n",
    "    \n",
    "    for j in range(TRAIN_FREQ//int(2*DT/DTI)):\n",
    "\n",
    "        observation = fireEnv.step()\n",
    "        \n",
    "        for d in range(N_DRONES):\n",
    "\n",
    "            state_vectors[d] = dronesEnv.drones[d].state\n",
    "            maps[d] = dronesEnv.drones[d].observation\n",
    "\n",
    "            state_vectors[d] = torch.tensor(state_vectors[d], device=device, dtype=torch.float)\n",
    "            maps[d] = torch.tensor(maps[d], device=device, dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(int(DT/DTI)):\n",
    "            \n",
    "            steps += 1\n",
    "\n",
    "            logits = [None]*N_DRONES\n",
    "            values = [None]*N_DRONES\n",
    "            actions = [None]*N_DRONES\n",
    "            old_m = [None]*N_DRONES\n",
    "            old_log_policy = [None]*N_DRONES\n",
    "            rewards = [None]*N_DRONES\n",
    "\n",
    "            for d in range(N_DRONES):\n",
    "\n",
    "                logits[d], values[d], hidden[d] = model(maps[d], state_vectors[d], hidden[d])\n",
    "                \n",
    "                policy = F.softmax(logits[d], dim=1)\n",
    "            \n",
    "                old_m[d] = Categorical(policy)\n",
    "    \n",
    "                actions[d] = old_m[d].sample()\n",
    "            \n",
    "                old_log_policy[d] = old_m[d].log_prob(actions[d])\n",
    "              \n",
    "    \n",
    "            rewards = dronesEnv.step([action.item() for action in actions], observation)\n",
    "            \n",
    "            \n",
    "            for d in range(N_DRONES):\n",
    "                memory[d].push(maps[d], state_vectors[d], actions[d], rewards[d], values[d].squeeze(), old_log_policy[d])\n",
    "                state_vectors[d] = dronesEnv.drones[d].state\n",
    "                maps[d] = dronesEnv.drones[d].observation\n",
    "\n",
    "                state_vectors[d] = torch.tensor(state_vectors[d], device=device, dtype=torch.float)\n",
    "                maps[d] = torch.tensor(maps[d], device=device, dtype=torch.float)\n",
    "\n",
    "            if not fireEnv.fire_in_range(6):\n",
    "\n",
    "                if i_episode % SAVE_MODEL == 0:\n",
    "                    file_path = f'./lstm_ppo_weights.pt'\n",
    "                    torch.save(model.state_dict(), file_path)\n",
    "                    print('saved')\n",
    "\n",
    "                for d in range(N_DRONES):\n",
    "                    _, next_value, _ = model(maps[d], state_vectors[d], hidden[d])\n",
    "\n",
    "                    next_value = next_value.squeeze()\n",
    "                    \n",
    "                    batch  = Transition(*zip(*memory[d].get_batch))\n",
    "\n",
    "\n",
    "                    old_log_policies_batch = torch.cat(batch.log_policy).detach()\n",
    "                \n",
    "\n",
    "                    actions_batch = torch.cat(batch.action)\n",
    "\n",
    "\n",
    "                    value_batch = torch.stack(batch.value).detach()\n",
    "                \n",
    "\n",
    "                    belief_map_batch = torch.cat(batch.belief_map)\n",
    "\n",
    "\n",
    "                    state_vector_batch = torch.cat(batch.state_vector)\n",
    "\n",
    "\n",
    "                    reward_batch = batch.reward \n",
    "                    \n",
    "                    gae = 0\n",
    "                    R = []\n",
    "\n",
    "                    for value, reward in list(zip(value_batch, reward_batch))[::-1]:\n",
    "                        gae = gae * GAMMA * TAU\n",
    "                        gae = gae + reward + GAMMA * next_value.detach() - value.detach()\n",
    "                        next_value = value\n",
    "                        R.append(gae + value)\n",
    "\n",
    "                    R = R[::-1]\n",
    "                    R = torch.stack(R).detach()\n",
    "                        \n",
    "                    advantages = R - value_batch\n",
    "\n",
    "                    indice = np.arange(0, len(memory[d]))\n",
    "                    indices = np.split(indice, np.arange(BATCH_SIZE, len(memory[d]),BATCH_SIZE))\n",
    "                    \n",
    "                    for e_i in range(EPOCHS):\n",
    "                        np.random.shuffle(indices)\n",
    "\n",
    "                        for batch_indices in indices:\n",
    "                            logits, value, _ = model(belief_map_batch[batch_indices], state_vector_batch[batch_indices], None, sequence_length=batch_indices.shape[0])\n",
    "                            new_policy = F.softmax(logits, dim=1)\n",
    "                            new_m = Categorical(new_policy)\n",
    "                            new_log_policy = new_m.log_prob(actions_batch[batch_indices])\n",
    "                            ratio = torch.exp(new_log_policy - old_log_policies_batch[batch_indices])\n",
    "                            \n",
    "                            actor_loss = -torch.mean(\n",
    "                                torch.min(ratio * advantages[batch_indices],\n",
    "                                    torch.clamp(ratio, 1.0 - EPSILON, 1.0 + EPSILON) *\n",
    "                                    advantages[batch_indices]\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "                            critic_loss = F.smooth_l1_loss(R[batch_indices], value.squeeze())\n",
    "                            entropy_loss = torch.mean(new_m.entropy())\n",
    "                            total_loss = actor_loss + critic_loss - BETA * entropy_loss\n",
    "                            optimizer.zero_grad()\n",
    "                            total_loss.backward()\n",
    "                            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "                            optimizer.step()\n",
    "\n",
    "                    print(\"Episode: {}. Total loss: {}\".format(i_episode, total_loss))\n",
    "                    memory[d].clear()\n",
    "                    hidden[d] = None\n",
    "                i_episode += 1\n",
    "                seed = fireEnv.reset()\n",
    "                dronesEnv.reset(seed)\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
