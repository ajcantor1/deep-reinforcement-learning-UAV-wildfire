{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting svgpath2mpl\n",
      "  Downloading svgpath2mpl-1.0.0-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (3.5.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (1.23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (4.34.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->svgpath2mpl) (1.14.0)\n",
      "Installing collected packages: svgpath2mpl\n",
      "Successfully installed svgpath2mpl-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install svgpath2mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adamax\n",
    "import random\n",
    "import math \n",
    "from svgpath2mpl import parse_path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.ndimage import rotate, shift\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from probabilistic_fire_env import ProbabilisticFireEnv\n",
    "from drone_env import DronesEnv\n",
    "from replay_memory import ReplayMemory, Transition\n",
    "from models.dqn import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = width = 100\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.1\n",
    "EPS_DECAY = 200000\n",
    "INIT_SIZE = 20000\n",
    "TARGET_UPDATE = 1000\n",
    "SAVE_POLICY = 100\n",
    "EPISODE_LENGTH = 250\n",
    "TRAIN_FREQ  = 10   # Number of samples to generate between trainings (Should be multiple of 10)\n",
    "PRINT_FREQ  = 100  # Frequency of printing (Should be a multiple of 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_actions = 2\n",
    "screen_height = screen_width = 100\n",
    "channels = 2\n",
    "policy_net = DQN(channels, screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(channels, screen_height, screen_width, n_actions).to(device)\n",
    "steps = 0\n",
    "policy_file_path = f'./policy_weights.pt'\n",
    "target_file_path = f'./target_weights.pt'\n",
    "\n",
    "#policy_net.load_state_dict(torch.load(policy_file_path))\n",
    "#target_net.load_state_dict(torch.load('target_weights.pt'))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "memory = ReplayMemory(70000)\n",
    "#memory.load()\n",
    "policy_net.train()\n",
    "target_net.eval()\n",
    "update_counter = 0\n",
    "optimizer = Adamax(policy_net.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(belief_map, state_vector, steps):\n",
    "  sample = random.random()\n",
    "  eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "    math.exp(-1. * steps / EPS_DECAY)\n",
    "\n",
    "  if sample > eps_threshold:\n",
    "    with torch.no_grad():\n",
    "      output = policy_net(belief_map, state_vector).max(1)[1].view(1, 1)\n",
    "      return output\n",
    "  else:\n",
    "    return torch.tensor([[random.randrange(2)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    \n",
    "    global update_counter\n",
    "    update_counter += 1\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    next_states = torch.cat(batch.next_state_vector)\n",
    "    next_belief_map = torch.cat(batch.next_belief_map)\n",
    "\n",
    "    belief_map_batch = torch.cat(batch.belief_map)\n",
    "    state_vector_batch = torch.cat(batch.state_vector)\n",
    "    \n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(belief_map_batch, state_vector_batch).gather(1, action_batch)\n",
    "    next_state_values = target_net(next_belief_map, next_states).max(1)[0].detach()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss().to(device)\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "    if update_counter % TARGET_UPDATE == 0:\n",
    "        policy_file_path = f'./policy_weights2.pt'\n",
    "        target_file_path = f'./target_weights2.pt'\n",
    "        torch.save(policy_net.state_dict(), policy_file_path)\n",
    "        torch.save(target_net.state_dict(), target_file_path)\n",
    "        print('update target')\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 episodes completed\n",
      "loss None\n",
      "steps done 1710\n",
      "10 episodes completed\n",
      "loss None\n",
      "steps done 5170\n",
      "15 episodes completed\n",
      "loss None\n",
      "steps done 9670\n",
      "20 episodes completed\n",
      "loss None\n",
      "steps done 14510\n",
      "25 episodes completed\n",
      "loss None\n",
      "steps done 17980\n",
      "30 episodes completed\n",
      "loss 0.6751432418823242\n",
      "steps done 21230\n",
      "35 episodes completed\n",
      "loss 0.8153688311576843\n",
      "steps done 25140\n",
      "40 episodes completed\n",
      "loss 0.6013771891593933\n",
      "steps done 28610\n",
      "update target\n",
      "45 episodes completed\n",
      "loss 0.4485732614994049\n",
      "steps done 32520\n",
      "50 episodes completed\n",
      "loss 0.47188690304756165\n",
      "steps done 36010\n",
      "55 episodes completed\n",
      "loss 0.48938125371932983\n",
      "steps done 39190\n",
      "update target\n",
      "60 episodes completed\n",
      "loss 0.4722789227962494\n",
      "steps done 43100\n",
      "65 episodes completed\n",
      "loss 0.33767175674438477\n",
      "steps done 47770\n",
      "update target\n",
      "70 episodes completed\n",
      "loss 1.1815670728683472\n",
      "steps done 51600\n",
      "75 episodes completed\n",
      "loss 0.6511623859405518\n",
      "steps done 55650\n",
      "80 episodes completed\n",
      "loss 0.8221272826194763\n",
      "steps done 59090\n",
      "update target\n",
      "85 episodes completed\n",
      "loss 0.6453620195388794\n",
      "steps done 63140\n",
      "90 episodes completed\n",
      "loss 0.6580501198768616\n",
      "steps done 66780\n",
      "95 episodes completed\n",
      "loss 0.8726122975349426\n",
      "steps done 69880\n",
      "update target\n",
      "100 episodes completed\n",
      "loss 0.7541577816009521\n",
      "steps done 73400\n",
      "105 episodes completed\n",
      "loss 0.6113986968994141\n",
      "steps done 76860\n",
      "update target\n",
      "110 episodes completed\n",
      "loss 0.9575294852256775\n",
      "steps done 81460\n",
      "115 episodes completed\n",
      "loss 1.4125455617904663\n",
      "steps done 84910\n",
      "120 episodes completed\n",
      "loss 1.631589412689209\n",
      "steps done 89520\n",
      "update target\n",
      "125 episodes completed\n",
      "loss 1.0353716611862183\n",
      "steps done 93670\n",
      "130 episodes completed\n",
      "loss 1.6407601833343506\n",
      "steps done 96770\n",
      "update target\n",
      "135 episodes completed\n",
      "loss 0.6998441815376282\n",
      "steps done 100370\n",
      "140 episodes completed\n",
      "loss 0.7455319762229919\n",
      "steps done 104160\n",
      "145 episodes completed\n",
      "loss 0.5880974531173706\n",
      "steps done 107390\n",
      "update target\n",
      "150 episodes completed\n",
      "loss 0.7166590094566345\n",
      "steps done 111510\n",
      "155 episodes completed\n",
      "loss 0.9877138733863831\n",
      "steps done 115870\n",
      "160 episodes completed\n",
      "loss 1.0197217464447021\n",
      "steps done 119050\n",
      "update target\n",
      "165 episodes completed\n",
      "loss 1.6273603439331055\n",
      "steps done 122830\n",
      "170 episodes completed\n",
      "loss 0.9929428696632385\n",
      "steps done 125820\n",
      "175 episodes completed\n",
      "loss 1.239814043045044\n",
      "steps done 129780\n",
      "update target\n",
      "180 episodes completed\n",
      "loss 0.5265666246414185\n",
      "steps done 133700\n",
      "185 episodes completed\n",
      "loss 1.073970913887024\n",
      "steps done 137660\n",
      "update target\n",
      "190 episodes completed\n",
      "loss 1.519175410270691\n",
      "steps done 141060\n",
      "195 episodes completed\n",
      "loss 1.143277645111084\n",
      "steps done 145980\n",
      "200 episodes completed\n",
      "loss 0.8619157075881958\n",
      "steps done 149580\n",
      "update target\n",
      "205 episodes completed\n",
      "loss 0.7495026588439941\n",
      "steps done 153840\n",
      "210 episodes completed\n",
      "loss 0.8525940179824829\n",
      "steps done 157310\n",
      "update target\n",
      "215 episodes completed\n",
      "loss 0.779727578163147\n",
      "steps done 160620\n",
      "220 episodes completed\n",
      "loss 1.420894742012024\n",
      "steps done 164570\n",
      "225 episodes completed\n",
      "loss 1.824985146522522\n",
      "steps done 168170\n",
      "update target\n",
      "230 episodes completed\n",
      "loss 1.4669020175933838\n",
      "steps done 171630\n",
      "235 episodes completed\n",
      "loss 0.8483813405036926\n",
      "steps done 175910\n",
      "240 episodes completed\n",
      "loss 1.277337670326233\n",
      "steps done 179750\n",
      "update target\n",
      "245 episodes completed\n",
      "loss 1.8759773969650269\n",
      "steps done 183420\n",
      "250 episodes completed\n",
      "loss 1.3817017078399658\n",
      "steps done 187030\n",
      "update target\n",
      "255 episodes completed\n",
      "loss 1.2634596824645996\n",
      "steps done 190630\n",
      "260 episodes completed\n",
      "loss 2.0836968421936035\n",
      "steps done 195100\n",
      "265 episodes completed\n",
      "loss 1.8756556510925293\n",
      "steps done 198610\n",
      "update target\n",
      "270 episodes completed\n",
      "loss 0.9921791553497314\n",
      "steps done 202580\n",
      "275 episodes completed\n",
      "loss 2.748704433441162\n",
      "steps done 206080\n",
      "280 episodes completed\n",
      "loss 0.9551773071289062\n",
      "steps done 209670\n",
      "update target\n",
      "285 episodes completed\n",
      "loss 2.7933144569396973\n",
      "steps done 214150\n",
      "290 episodes completed\n",
      "loss 2.4730467796325684\n",
      "steps done 217260\n",
      "update target\n",
      "295 episodes completed\n",
      "loss 2.6762232780456543\n",
      "steps done 221660\n",
      "300 episodes completed\n",
      "loss 2.883911609649658\n",
      "steps done 225430\n",
      "305 episodes completed\n",
      "loss 2.1553401947021484\n",
      "steps done 229220\n",
      "update target\n",
      "310 episodes completed\n",
      "loss 2.668473482131958\n",
      "steps done 233870\n",
      "315 episodes completed\n",
      "loss 2.053776741027832\n",
      "steps done 237820\n",
      "update target\n",
      "320 episodes completed\n",
      "loss 2.0496702194213867\n",
      "steps done 241520\n",
      "325 episodes completed\n",
      "loss 2.737232208251953\n",
      "steps done 245310\n",
      "330 episodes completed\n",
      "loss 2.512139320373535\n",
      "steps done 248950\n",
      "update target\n",
      "335 episodes completed\n",
      "loss 2.92510986328125\n",
      "steps done 253080\n",
      "340 episodes completed\n",
      "loss 2.562803268432617\n",
      "steps done 256250\n",
      "345 episodes completed\n",
      "loss 2.514153003692627\n",
      "steps done 259660\n",
      "update target\n",
      "350 episodes completed\n",
      "loss 3.1008481979370117\n",
      "steps done 263480\n",
      "355 episodes completed\n",
      "loss 2.9388771057128906\n",
      "steps done 266880\n",
      "update target\n",
      "360 episodes completed\n",
      "loss 2.0784621238708496\n",
      "steps done 270920\n",
      "365 episodes completed\n",
      "loss 4.124847412109375\n",
      "steps done 274660\n",
      "370 episodes completed\n",
      "loss 3.0332276821136475\n",
      "steps done 278890\n",
      "update target\n",
      "375 episodes completed\n",
      "loss 4.166743278503418\n",
      "steps done 282800\n",
      "380 episodes completed\n",
      "loss 3.5522689819335938\n",
      "steps done 286510\n",
      "update target\n",
      "385 episodes completed\n",
      "loss 3.5926876068115234\n",
      "steps done 290330\n",
      "390 episodes completed\n",
      "loss 4.129135608673096\n",
      "steps done 293940\n",
      "395 episodes completed\n",
      "loss 4.262126922607422\n",
      "steps done 297400\n",
      "update target\n",
      "400 episodes completed\n",
      "loss 4.6140241622924805\n",
      "steps done 300420\n",
      "405 episodes completed\n",
      "loss 4.9020185470581055\n",
      "steps done 304060\n",
      "410 episodes completed\n",
      "loss 3.7499351501464844\n",
      "steps done 307380\n",
      "update target\n",
      "415 episodes completed\n",
      "loss 4.174912452697754\n",
      "steps done 311190\n",
      "420 episodes completed\n",
      "loss 5.065080642700195\n",
      "steps done 315420\n",
      "425 episodes completed\n",
      "loss 4.348292350769043\n",
      "steps done 319110\n",
      "update target\n",
      "430 episodes completed\n",
      "loss 4.748098850250244\n",
      "steps done 322910\n",
      "435 episodes completed\n",
      "loss 4.204218864440918\n",
      "steps done 326620\n",
      "update target\n",
      "440 episodes completed\n",
      "loss 3.8495872020721436\n",
      "steps done 330250\n",
      "445 episodes completed\n",
      "loss 4.1964216232299805\n",
      "steps done 334040\n",
      "450 episodes completed\n",
      "loss 4.025033950805664\n",
      "steps done 337700\n",
      "update target\n",
      "455 episodes completed\n",
      "loss 4.799723148345947\n",
      "steps done 341490\n",
      "460 episodes completed\n",
      "loss 5.534191131591797\n",
      "steps done 345260\n",
      "465 episodes completed\n",
      "loss 4.101736545562744\n",
      "steps done 349460\n",
      "update target\n",
      "470 episodes completed\n",
      "loss 3.6436381340026855\n",
      "steps done 352970\n",
      "475 episodes completed\n",
      "loss 3.719560384750366\n",
      "steps done 356940\n",
      "update target\n",
      "480 episodes completed\n",
      "loss 4.053978443145752\n",
      "steps done 360270\n",
      "485 episodes completed\n",
      "loss 5.636500358581543\n",
      "steps done 364140\n",
      "490 episodes completed\n",
      "loss 4.291706562042236\n",
      "steps done 368450\n",
      "update target\n",
      "495 episodes completed\n",
      "loss 4.810421943664551\n",
      "steps done 372260\n",
      "500 episodes completed\n",
      "loss 4.099435806274414\n",
      "steps done 376200\n",
      "update target\n",
      "505 episodes completed\n",
      "loss 5.48633337020874\n",
      "steps done 380820\n",
      "510 episodes completed\n",
      "loss 5.754573822021484\n",
      "steps done 384430\n",
      "515 episodes completed\n",
      "loss 4.998076438903809\n",
      "steps done 388430\n",
      "update target\n",
      "520 episodes completed\n",
      "loss 4.741987705230713\n",
      "steps done 391910\n",
      "525 episodes completed\n",
      "loss 6.793933868408203\n",
      "steps done 395320\n",
      "530 episodes completed\n",
      "loss 4.40451717376709\n",
      "steps done 399200\n",
      "update target\n",
      "535 episodes completed\n",
      "loss 5.0908050537109375\n",
      "steps done 403170\n",
      "540 episodes completed\n",
      "loss 4.146566390991211\n",
      "steps done 406800\n",
      "update target\n",
      "545 episodes completed\n",
      "loss 4.700260639190674\n",
      "steps done 410510\n",
      "550 episodes completed\n",
      "loss 5.294126987457275\n",
      "steps done 414560\n",
      "555 episodes completed\n",
      "loss 4.763096809387207\n",
      "steps done 418680\n",
      "update target\n",
      "560 episodes completed\n",
      "loss 5.568099498748779\n",
      "steps done 421960\n",
      "565 episodes completed\n",
      "loss 4.324492454528809\n",
      "steps done 425880\n",
      "update target\n",
      "570 episodes completed\n",
      "loss 5.613093852996826\n",
      "steps done 430040\n",
      "575 episodes completed\n",
      "loss 4.899999618530273\n",
      "steps done 433960\n",
      "580 episodes completed\n",
      "loss 6.309062957763672\n",
      "steps done 437770\n",
      "update target\n",
      "585 episodes completed\n",
      "loss 5.831562519073486\n",
      "steps done 441180\n",
      "590 episodes completed\n",
      "loss 4.800400733947754\n",
      "steps done 444840\n",
      "595 episodes completed\n",
      "loss 6.0846476554870605\n",
      "steps done 448080\n",
      "update target\n",
      "600 episodes completed\n",
      "loss 5.980075836181641\n",
      "steps done 451330\n",
      "605 episodes completed\n",
      "loss 6.5909528732299805\n",
      "steps done 455090\n",
      "610 episodes completed\n",
      "loss 4.387540817260742\n",
      "steps done 458520\n",
      "update target\n",
      "615 episodes completed\n",
      "loss 6.890349388122559\n",
      "steps done 461930\n",
      "620 episodes completed\n",
      "loss 4.470752716064453\n",
      "steps done 465800\n",
      "update target\n",
      "625 episodes completed\n",
      "loss 7.037722587585449\n",
      "steps done 470180\n",
      "630 episodes completed\n",
      "loss 5.556670665740967\n",
      "steps done 473740\n",
      "635 episodes completed\n",
      "loss 5.650167465209961\n",
      "steps done 476930\n",
      "update target\n",
      "640 episodes completed\n",
      "loss 5.409111499786377\n",
      "steps done 482150\n",
      "645 episodes completed\n",
      "loss 5.635397911071777\n",
      "steps done 485940\n",
      "update target\n",
      "650 episodes completed\n",
      "loss 5.303959369659424\n",
      "steps done 490620\n",
      "655 episodes completed\n",
      "loss 6.375082015991211\n",
      "steps done 494430\n",
      "660 episodes completed\n",
      "loss 5.346879959106445\n",
      "steps done 497920\n",
      "update target\n",
      "665 episodes completed\n",
      "loss 6.226558685302734\n",
      "steps done 501980\n",
      "670 episodes completed\n",
      "loss 6.051469802856445\n",
      "steps done 506100\n",
      "675 episodes completed\n",
      "loss 5.094370365142822\n",
      "steps done 509700\n",
      "update target\n",
      "680 episodes completed\n",
      "loss 5.853791236877441\n",
      "steps done 513910\n",
      "685 episodes completed\n",
      "loss 5.523843765258789\n",
      "steps done 517750\n",
      "update target\n",
      "690 episodes completed\n",
      "loss 5.925507545471191\n",
      "steps done 521440\n",
      "695 episodes completed\n",
      "loss 6.558169364929199\n",
      "steps done 525270\n",
      "700 episodes completed\n",
      "loss 5.76029109954834\n",
      "steps done 529590\n",
      "update target\n",
      "705 episodes completed\n",
      "loss 5.4902544021606445\n",
      "steps done 533010\n",
      "710 episodes completed\n",
      "loss 5.01500129699707\n",
      "steps done 537110\n",
      "update target\n",
      "715 episodes completed\n",
      "loss 6.025752067565918\n",
      "steps done 541490\n",
      "720 episodes completed\n",
      "loss 5.705503940582275\n",
      "steps done 544970\n",
      "725 episodes completed\n",
      "loss 5.320762634277344\n",
      "steps done 548560\n",
      "update target\n",
      "730 episodes completed\n",
      "loss 6.572965621948242\n",
      "steps done 552040\n",
      "735 episodes completed\n",
      "loss 5.220254898071289\n",
      "steps done 555760\n",
      "740 episodes completed\n",
      "loss 5.802426338195801\n",
      "steps done 559430\n",
      "update target\n",
      "745 episodes completed\n",
      "loss 7.005707740783691\n",
      "steps done 562740\n",
      "750 episodes completed\n",
      "loss 6.30404806137085\n",
      "steps done 565980\n",
      "755 episodes completed\n",
      "loss 5.177626609802246\n",
      "steps done 569880\n",
      "update target\n",
      "760 episodes completed\n",
      "loss 5.8581037521362305\n",
      "steps done 573330\n",
      "765 episodes completed\n",
      "loss 4.9039764404296875\n",
      "steps done 576580\n",
      "update target\n",
      "770 episodes completed\n",
      "loss 5.632034778594971\n",
      "steps done 580500\n",
      "775 episodes completed\n",
      "loss 4.482970237731934\n",
      "steps done 584270\n",
      "780 episodes completed\n",
      "loss 5.984312057495117\n",
      "steps done 587720\n",
      "update target\n",
      "785 episodes completed\n",
      "loss 6.250609397888184\n",
      "steps done 591060\n",
      "790 episodes completed\n",
      "loss 5.166826248168945\n",
      "steps done 594980\n",
      "795 episodes completed\n",
      "loss 5.09108829498291\n",
      "steps done 599530\n",
      "update target\n",
      "800 episodes completed\n",
      "loss 5.434898376464844\n",
      "steps done 603130\n",
      "805 episodes completed\n",
      "loss 5.272509574890137\n",
      "steps done 606770\n",
      "update target\n",
      "810 episodes completed\n",
      "loss 4.706003665924072\n",
      "steps done 610340\n",
      "815 episodes completed\n",
      "loss 5.677814960479736\n",
      "steps done 614020\n",
      "820 episodes completed\n",
      "loss 5.200795650482178\n",
      "steps done 617050\n",
      "update target\n",
      "825 episodes completed\n",
      "loss 5.182363986968994\n",
      "steps done 621490\n",
      "830 episodes completed\n",
      "loss 5.873437881469727\n",
      "steps done 624770\n",
      "835 episodes completed\n",
      "loss 5.6890764236450195\n",
      "steps done 628460\n",
      "update target\n",
      "840 episodes completed\n",
      "loss 5.296391487121582\n",
      "steps done 632120\n",
      "845 episodes completed\n",
      "loss 6.790323257446289\n",
      "steps done 635470\n",
      "850 episodes completed\n",
      "loss 5.276522636413574\n",
      "steps done 639210\n",
      "update target\n",
      "855 episodes completed\n",
      "loss 6.078473091125488\n",
      "steps done 642570\n",
      "860 episodes completed\n",
      "loss 6.214968681335449\n",
      "steps done 646610\n",
      "update target\n",
      "865 episodes completed\n",
      "loss 4.70222282409668\n",
      "steps done 650000\n",
      "870 episodes completed\n",
      "loss 5.899093151092529\n",
      "steps done 653820\n",
      "875 episodes completed\n",
      "loss 4.494856834411621\n",
      "steps done 658000\n",
      "update target\n",
      "880 episodes completed\n",
      "loss 6.654034614562988\n",
      "steps done 661850\n",
      "885 episodes completed\n",
      "loss 6.073951721191406\n",
      "steps done 666050\n",
      "890 episodes completed\n",
      "loss 5.299477577209473\n",
      "steps done 669720\n",
      "update target\n",
      "895 episodes completed\n",
      "loss 5.722991943359375\n",
      "steps done 673520\n",
      "900 episodes completed\n",
      "loss 6.737868785858154\n",
      "steps done 677870\n",
      "update target\n",
      "905 episodes completed\n",
      "loss 6.67482852935791\n",
      "steps done 681390\n",
      "910 episodes completed\n",
      "loss 4.919584274291992\n",
      "steps done 685730\n",
      "915 episodes completed\n",
      "loss 5.659804344177246\n",
      "steps done 689480\n",
      "update target\n",
      "920 episodes completed\n",
      "loss 6.724321365356445\n",
      "steps done 692850\n",
      "925 episodes completed\n",
      "loss 5.404533386230469\n",
      "steps done 696150\n",
      "930 episodes completed\n",
      "loss 6.866297721862793\n",
      "steps done 699190\n",
      "update target\n",
      "935 episodes completed\n",
      "loss 7.156658172607422\n",
      "steps done 702500\n",
      "940 episodes completed\n",
      "loss 5.6782612800598145\n",
      "steps done 706730\n",
      "update target\n",
      "945 episodes completed\n",
      "loss 9.26058292388916\n",
      "steps done 710220\n",
      "950 episodes completed\n",
      "loss 6.277374267578125\n",
      "steps done 714320\n",
      "955 episodes completed\n",
      "loss 6.21973991394043\n",
      "steps done 718340\n",
      "update target\n",
      "960 episodes completed\n",
      "loss 5.722807884216309\n",
      "steps done 722180\n",
      "965 episodes completed\n",
      "loss 6.643950462341309\n",
      "steps done 725700\n",
      "970 episodes completed\n",
      "loss 6.5517964363098145\n",
      "steps done 729720\n",
      "update target\n",
      "975 episodes completed\n",
      "loss 6.556725025177002\n",
      "steps done 733100\n",
      "980 episodes completed\n",
      "loss 5.946260452270508\n",
      "steps done 736520\n",
      "update target\n",
      "985 episodes completed\n",
      "loss 6.061309814453125\n",
      "steps done 740610\n",
      "990 episodes completed\n",
      "loss 7.023366451263428\n",
      "steps done 744610\n",
      "995 episodes completed\n",
      "loss 5.610209941864014\n",
      "steps done 748170\n",
      "update target\n",
      "1000 episodes completed\n",
      "loss 6.3263936042785645\n",
      "steps done 751900\n",
      "1005 episodes completed\n",
      "loss 6.69383430480957\n",
      "steps done 755400\n",
      "1010 episodes completed\n",
      "loss 5.4204864501953125\n",
      "steps done 759550\n",
      "update target\n",
      "1015 episodes completed\n",
      "loss 5.881987571716309\n",
      "steps done 763650\n",
      "1020 episodes completed\n",
      "loss 6.491578102111816\n",
      "steps done 767050\n",
      "update target\n",
      "1025 episodes completed\n",
      "loss 6.714476585388184\n",
      "steps done 771400\n",
      "1030 episodes completed\n",
      "loss 6.097824573516846\n",
      "steps done 774870\n",
      "1035 episodes completed\n",
      "loss 6.1536664962768555\n",
      "steps done 778490\n",
      "update target\n",
      "1040 episodes completed\n",
      "loss 6.164361000061035\n",
      "steps done 782330\n",
      "1045 episodes completed\n",
      "loss 6.815057277679443\n",
      "steps done 786300\n",
      "update target\n",
      "1050 episodes completed\n",
      "loss 6.427595138549805\n",
      "steps done 790040\n",
      "1055 episodes completed\n",
      "loss 6.614380836486816\n",
      "steps done 793890\n",
      "1060 episodes completed\n",
      "loss 5.920385360717773\n",
      "steps done 797510\n",
      "update target\n",
      "1065 episodes completed\n",
      "loss 5.8607072830200195\n",
      "steps done 801380\n",
      "1070 episodes completed\n",
      "loss 5.89867639541626\n",
      "steps done 805200\n",
      "1075 episodes completed\n",
      "loss 5.767871856689453\n",
      "steps done 809260\n",
      "update target\n",
      "1080 episodes completed\n",
      "loss 6.183971405029297\n",
      "steps done 813490\n",
      "1085 episodes completed\n",
      "loss 5.973387718200684\n",
      "steps done 816630\n",
      "update target\n",
      "1090 episodes completed\n",
      "loss 5.771951198577881\n",
      "steps done 820110\n",
      "1095 episodes completed\n",
      "loss 6.445652484893799\n",
      "steps done 824590\n",
      "1100 episodes completed\n",
      "loss 6.9899702072143555\n",
      "steps done 828440\n",
      "update target\n",
      "1105 episodes completed\n",
      "loss 6.466076850891113\n",
      "steps done 831820\n",
      "1110 episodes completed\n",
      "loss 6.683650016784668\n",
      "steps done 835930\n",
      "1115 episodes completed\n",
      "loss 6.657377243041992\n",
      "steps done 839540\n",
      "update target\n",
      "1120 episodes completed\n",
      "loss 6.568338394165039\n",
      "steps done 843440\n",
      "1125 episodes completed\n",
      "loss 6.414101600646973\n",
      "steps done 846790\n",
      "update target\n",
      "1130 episodes completed\n",
      "loss 6.224557399749756\n",
      "steps done 850300\n",
      "1135 episodes completed\n",
      "loss 6.242027282714844\n",
      "steps done 854150\n",
      "1140 episodes completed\n",
      "loss 4.726178169250488\n",
      "steps done 857540\n",
      "update target\n",
      "1145 episodes completed\n",
      "loss 5.774260520935059\n",
      "steps done 861180\n",
      "1150 episodes completed\n",
      "loss 6.452786445617676\n",
      "steps done 865320\n",
      "1155 episodes completed\n",
      "loss 5.6332292556762695\n",
      "steps done 868940\n",
      "update target\n",
      "1160 episodes completed\n",
      "loss 6.570283889770508\n",
      "steps done 872810\n",
      "1165 episodes completed\n",
      "loss 6.108950614929199\n",
      "steps done 876890\n",
      "update target\n",
      "1170 episodes completed\n",
      "loss 7.004385948181152\n",
      "steps done 881050\n",
      "1175 episodes completed\n",
      "loss 6.631671905517578\n",
      "steps done 884620\n",
      "1180 episodes completed\n",
      "loss 6.784156799316406\n",
      "steps done 888200\n",
      "update target\n",
      "1185 episodes completed\n",
      "loss 6.550314903259277\n",
      "steps done 891800\n",
      "1190 episodes completed\n",
      "loss 5.509217262268066\n",
      "steps done 895730\n",
      "1195 episodes completed\n",
      "loss 6.986855506896973\n",
      "steps done 899400\n",
      "update target\n",
      "1200 episodes completed\n",
      "loss 6.33720064163208\n",
      "steps done 902790\n",
      "1205 episodes completed\n",
      "loss 6.100683212280273\n",
      "steps done 906600\n",
      "1210 episodes completed\n",
      "loss 6.144680500030518\n",
      "steps done 909800\n",
      "update target\n",
      "1215 episodes completed\n",
      "loss 6.206117630004883\n",
      "steps done 913380\n",
      "1220 episodes completed\n",
      "loss 6.25649356842041\n",
      "steps done 917610\n",
      "update target\n",
      "1225 episodes completed\n",
      "loss 5.846253395080566\n",
      "steps done 921310\n",
      "1230 episodes completed\n",
      "loss 5.164239883422852\n",
      "steps done 924770\n",
      "1235 episodes completed\n",
      "loss 6.12546968460083\n",
      "steps done 928230\n",
      "update target\n",
      "1240 episodes completed\n",
      "loss 6.52528715133667\n",
      "steps done 932230\n",
      "1245 episodes completed\n",
      "loss 5.641357898712158\n",
      "steps done 935790\n",
      "1250 episodes completed\n",
      "loss 7.3846025466918945\n",
      "steps done 939230\n",
      "update target\n",
      "1255 episodes completed\n",
      "loss 5.663329124450684\n",
      "steps done 943020\n",
      "1260 episodes completed\n",
      "loss 6.559680938720703\n",
      "steps done 946700\n",
      "update target\n",
      "1265 episodes completed\n",
      "loss 6.8654937744140625\n",
      "steps done 951010\n",
      "1270 episodes completed\n",
      "loss 5.98890495300293\n",
      "steps done 954490\n",
      "1275 episodes completed\n",
      "loss 7.131898880004883\n",
      "steps done 958250\n",
      "update target\n",
      "1280 episodes completed\n",
      "loss 6.760066509246826\n",
      "steps done 962250\n",
      "1285 episodes completed\n",
      "loss 6.709250450134277\n",
      "steps done 966140\n",
      "update target\n",
      "1290 episodes completed\n",
      "loss 6.184788703918457\n",
      "steps done 970410\n",
      "1295 episodes completed\n",
      "loss 5.869008541107178\n",
      "steps done 973810\n",
      "1300 episodes completed\n",
      "loss 6.943698883056641\n",
      "steps done 977510\n",
      "update target\n",
      "1305 episodes completed\n",
      "loss 7.315903663635254\n",
      "steps done 981420\n",
      "1310 episodes completed\n",
      "loss 6.147874355316162\n",
      "steps done 985100\n",
      "1315 episodes completed\n",
      "loss 6.609214782714844\n",
      "steps done 988440\n",
      "update target\n",
      "1320 episodes completed\n",
      "loss 6.948998928070068\n",
      "steps done 992080\n",
      "1325 episodes completed\n",
      "loss 5.7661824226379395\n",
      "steps done 995850\n",
      "1330 episodes completed\n",
      "loss 5.831479072570801\n",
      "steps done 999200\n",
      "update target\n",
      "1335 episodes completed\n",
      "loss 5.830402374267578\n",
      "steps done 1003250\n",
      "1340 episodes completed\n",
      "loss 6.861825942993164\n",
      "steps done 1007110\n",
      "update target\n",
      "1345 episodes completed\n",
      "loss 5.142982482910156\n",
      "steps done 1010490\n",
      "1350 episodes completed\n",
      "loss 5.544836521148682\n",
      "steps done 1013850\n",
      "1355 episodes completed\n",
      "loss 6.277189254760742\n",
      "steps done 1017890\n",
      "update target\n",
      "1360 episodes completed\n",
      "loss 5.664927959442139\n",
      "steps done 1021550\n",
      "1365 episodes completed\n",
      "loss 6.129240989685059\n",
      "steps done 1025110\n",
      "1370 episodes completed\n",
      "loss 6.843453407287598\n",
      "steps done 1028170\n",
      "update target\n",
      "1375 episodes completed\n",
      "loss 5.835484981536865\n",
      "steps done 1031950\n",
      "1380 episodes completed\n",
      "loss 5.351027488708496\n",
      "steps done 1035360\n",
      "1385 episodes completed\n",
      "loss 7.081758975982666\n",
      "steps done 1039050\n",
      "update target\n",
      "1390 episodes completed\n",
      "loss 7.167115211486816\n",
      "steps done 1042120\n",
      "1395 episodes completed\n",
      "loss 6.417296886444092\n",
      "steps done 1045840\n",
      "1400 episodes completed\n",
      "loss 6.20594596862793\n",
      "steps done 1049750\n",
      "update target\n",
      "1405 episodes completed\n",
      "loss 5.678842544555664\n",
      "steps done 1052840\n",
      "1410 episodes completed\n",
      "loss 6.511765003204346\n",
      "steps done 1056470\n",
      "1415 episodes completed\n",
      "loss 5.666566848754883\n",
      "steps done 1059980\n",
      "update target\n",
      "1420 episodes completed\n",
      "loss 5.8686017990112305\n",
      "steps done 1063200\n",
      "1425 episodes completed\n",
      "loss 6.119115829467773\n",
      "steps done 1066780\n",
      "update target\n",
      "1430 episodes completed\n",
      "loss 7.26843786239624\n",
      "steps done 1070870\n",
      "1435 episodes completed\n",
      "loss 6.984358787536621\n",
      "steps done 1074610\n",
      "1440 episodes completed\n",
      "loss 6.042334079742432\n",
      "steps done 1078840\n",
      "update target\n",
      "1445 episodes completed\n",
      "loss 7.887038230895996\n",
      "steps done 1082610\n",
      "1450 episodes completed\n",
      "loss 6.5955681800842285\n",
      "steps done 1086750\n",
      "update target\n",
      "1455 episodes completed\n",
      "loss 6.9431538581848145\n",
      "steps done 1090060\n",
      "1460 episodes completed\n",
      "loss 5.7579827308654785\n",
      "steps done 1094150\n",
      "1465 episodes completed\n",
      "loss 6.211816787719727\n",
      "steps done 1097950\n",
      "update target\n",
      "1470 episodes completed\n",
      "loss 6.01564884185791\n",
      "steps done 1101120\n",
      "1475 episodes completed\n",
      "loss 5.173079967498779\n",
      "steps done 1105510\n",
      "1480 episodes completed\n",
      "loss 6.539582252502441\n",
      "steps done 1109750\n",
      "update target\n",
      "1485 episodes completed\n",
      "loss 5.6613545417785645\n",
      "steps done 1113370\n",
      "1490 episodes completed\n",
      "loss 6.083727836608887\n",
      "steps done 1117460\n",
      "update target\n",
      "1495 episodes completed\n",
      "loss 6.6964874267578125\n",
      "steps done 1121940\n",
      "1500 episodes completed\n",
      "loss 5.558623313903809\n",
      "steps done 1125850\n",
      "1505 episodes completed\n",
      "loss 6.230557441711426\n",
      "steps done 1129070\n",
      "update target\n",
      "1510 episodes completed\n",
      "loss 6.086905479431152\n",
      "steps done 1132950\n",
      "1515 episodes completed\n",
      "loss 5.474353790283203\n",
      "steps done 1137200\n",
      "update target\n",
      "1520 episodes completed\n",
      "loss 5.581595420837402\n",
      "steps done 1140680\n",
      "1525 episodes completed\n",
      "loss 7.0911102294921875\n",
      "steps done 1144670\n",
      "1530 episodes completed\n",
      "loss 6.027093887329102\n",
      "steps done 1149130\n",
      "update target\n",
      "1535 episodes completed\n",
      "loss 7.351107120513916\n",
      "steps done 1152470\n",
      "1540 episodes completed\n",
      "loss 6.6487932205200195\n",
      "steps done 1156050\n",
      "1545 episodes completed\n",
      "loss 6.545032501220703\n",
      "steps done 1159990\n",
      "update target\n",
      "1550 episodes completed\n",
      "loss 6.760031700134277\n",
      "steps done 1163810\n",
      "1555 episodes completed\n",
      "loss 5.3681488037109375\n",
      "steps done 1167200\n",
      "update target\n",
      "1560 episodes completed\n",
      "loss 6.543617248535156\n",
      "steps done 1171510\n",
      "1565 episodes completed\n",
      "loss 6.976440906524658\n",
      "steps done 1175550\n",
      "update target\n",
      "1570 episodes completed\n",
      "loss 8.237278938293457\n",
      "steps done 1180230\n",
      "1575 episodes completed\n",
      "loss 5.876766204833984\n",
      "steps done 1183760\n",
      "1580 episodes completed\n",
      "loss 6.240991115570068\n",
      "steps done 1188160\n",
      "update target\n",
      "1585 episodes completed\n",
      "loss 6.3980817794799805\n",
      "steps done 1192170\n",
      "1590 episodes completed\n",
      "loss 6.8000288009643555\n",
      "steps done 1195230\n",
      "1595 episodes completed\n",
      "loss 6.040722846984863\n",
      "steps done 1198200\n",
      "update target\n",
      "1600 episodes completed\n",
      "loss 6.868327617645264\n",
      "steps done 1201540\n",
      "1605 episodes completed\n",
      "loss 7.071643829345703\n",
      "steps done 1205900\n",
      "1610 episodes completed\n",
      "loss 6.309737205505371\n",
      "steps done 1209500\n",
      "update target\n",
      "1615 episodes completed\n",
      "loss 8.128124237060547\n",
      "steps done 1213460\n",
      "1620 episodes completed\n",
      "loss 6.1991400718688965\n",
      "steps done 1217650\n",
      "update target\n",
      "1625 episodes completed\n",
      "loss 7.309194564819336\n",
      "steps done 1221840\n",
      "1630 episodes completed\n",
      "loss 6.258379936218262\n",
      "steps done 1225390\n",
      "1635 episodes completed\n",
      "loss 6.780678749084473\n",
      "steps done 1229460\n",
      "update target\n",
      "1640 episodes completed\n",
      "loss 5.165407180786133\n",
      "steps done 1233390\n",
      "1645 episodes completed\n",
      "loss 5.889218330383301\n",
      "steps done 1236920\n",
      "update target\n",
      "1650 episodes completed\n",
      "loss 8.027024269104004\n",
      "steps done 1240160\n",
      "1655 episodes completed\n",
      "loss 6.510407447814941\n",
      "steps done 1243920\n",
      "1660 episodes completed\n",
      "loss 7.270677089691162\n",
      "steps done 1247170\n",
      "update target\n",
      "1665 episodes completed\n",
      "loss 6.882778167724609\n",
      "steps done 1250620\n",
      "1670 episodes completed\n",
      "loss 5.539188385009766\n",
      "steps done 1254440\n",
      "1675 episodes completed\n",
      "loss 6.061578273773193\n",
      "steps done 1258600\n",
      "update target\n",
      "1680 episodes completed\n",
      "loss 5.899261951446533\n",
      "steps done 1261860\n",
      "1685 episodes completed\n",
      "loss 6.146204948425293\n",
      "steps done 1266110\n",
      "update target\n",
      "1690 episodes completed\n",
      "loss 6.658975601196289\n",
      "steps done 1270070\n",
      "1695 episodes completed\n",
      "loss 6.0519022941589355\n",
      "steps done 1273570\n",
      "1700 episodes completed\n",
      "loss 5.691464424133301\n",
      "steps done 1277600\n",
      "update target\n",
      "1705 episodes completed\n",
      "loss 5.783123016357422\n",
      "steps done 1281060\n",
      "1710 episodes completed\n",
      "loss 6.527755260467529\n",
      "steps done 1284750\n",
      "1715 episodes completed\n",
      "loss 6.6697096824646\n",
      "steps done 1288980\n",
      "update target\n",
      "1720 episodes completed\n",
      "loss 7.662477493286133\n",
      "steps done 1292450\n",
      "1725 episodes completed\n",
      "loss 5.640009880065918\n",
      "steps done 1296620\n",
      "update target\n",
      "1730 episodes completed\n",
      "loss 5.962770462036133\n",
      "steps done 1300910\n",
      "1735 episodes completed\n",
      "loss 6.178330898284912\n",
      "steps done 1304290\n",
      "1740 episodes completed\n",
      "loss 5.530056953430176\n",
      "steps done 1308140\n",
      "update target\n",
      "1745 episodes completed\n",
      "loss 6.065553665161133\n",
      "steps done 1311910\n",
      "1750 episodes completed\n",
      "loss 6.373717308044434\n",
      "steps done 1315900\n",
      "1755 episodes completed\n",
      "loss 5.8598175048828125\n",
      "steps done 1319660\n",
      "update target\n",
      "1760 episodes completed\n",
      "loss 6.8370842933654785\n",
      "steps done 1323130\n",
      "1765 episodes completed\n",
      "loss 6.324212074279785\n",
      "steps done 1327450\n",
      "update target\n",
      "1770 episodes completed\n",
      "loss 6.079155921936035\n",
      "steps done 1331010\n",
      "1775 episodes completed\n",
      "loss 5.435136795043945\n",
      "steps done 1334980\n",
      "1780 episodes completed\n",
      "loss 6.864348888397217\n",
      "steps done 1339040\n",
      "update target\n",
      "1785 episodes completed\n",
      "loss 5.9510698318481445\n",
      "steps done 1342780\n",
      "1790 episodes completed\n",
      "loss 4.996501922607422\n",
      "steps done 1346970\n",
      "update target\n",
      "1795 episodes completed\n",
      "loss 5.9153289794921875\n",
      "steps done 1350040\n",
      "1800 episodes completed\n",
      "loss 6.400068283081055\n",
      "steps done 1353410\n",
      "1805 episodes completed\n",
      "loss 6.413291931152344\n",
      "steps done 1357730\n",
      "update target\n",
      "1810 episodes completed\n",
      "loss 5.91269588470459\n",
      "steps done 1361530\n",
      "1815 episodes completed\n",
      "loss 6.006484508514404\n",
      "steps done 1365840\n",
      "1820 episodes completed\n",
      "loss 5.873138427734375\n",
      "steps done 1369410\n",
      "update target\n",
      "1825 episodes completed\n",
      "loss 5.0001115798950195\n",
      "steps done 1372970\n",
      "1830 episodes completed\n",
      "loss 5.9764404296875\n",
      "steps done 1376560\n",
      "update target\n",
      "1835 episodes completed\n",
      "loss 6.111540794372559\n",
      "steps done 1380050\n",
      "1840 episodes completed\n",
      "loss 5.179426670074463\n",
      "steps done 1383580\n",
      "1845 episodes completed\n",
      "loss 5.017809867858887\n",
      "steps done 1387060\n",
      "update target\n",
      "1850 episodes completed\n",
      "loss 6.139352798461914\n",
      "steps done 1390010\n",
      "1855 episodes completed\n",
      "loss 5.651216506958008\n",
      "steps done 1394290\n",
      "1860 episodes completed\n",
      "loss 6.0923237800598145\n",
      "steps done 1398420\n",
      "update target\n",
      "1865 episodes completed\n",
      "loss 5.291012287139893\n",
      "steps done 1402490\n",
      "1870 episodes completed\n",
      "loss 6.355801582336426\n",
      "steps done 1407030\n",
      "update target\n",
      "1875 episodes completed\n",
      "loss 6.271751880645752\n",
      "steps done 1410580\n",
      "1880 episodes completed\n",
      "loss 5.932070732116699\n",
      "steps done 1414400\n",
      "1885 episodes completed\n",
      "loss 5.653017997741699\n",
      "steps done 1417790\n",
      "update target\n",
      "1890 episodes completed\n",
      "loss 5.426619529724121\n",
      "steps done 1421120\n",
      "1895 episodes completed\n",
      "loss 5.5944671630859375\n",
      "steps done 1424580\n",
      "1900 episodes completed\n",
      "loss 4.988892555236816\n",
      "steps done 1428010\n",
      "update target\n",
      "1905 episodes completed\n",
      "loss 6.819528579711914\n",
      "steps done 1431330\n",
      "1910 episodes completed\n",
      "loss 5.142634868621826\n",
      "steps done 1434820\n",
      "1915 episodes completed\n",
      "loss 5.325959205627441\n",
      "steps done 1438570\n",
      "update target\n",
      "1920 episodes completed\n",
      "loss 5.515815258026123\n",
      "steps done 1441790\n",
      "1925 episodes completed\n",
      "loss 6.371904373168945\n",
      "steps done 1445790\n",
      "update target\n",
      "1930 episodes completed\n",
      "loss 6.814004898071289\n",
      "steps done 1450230\n",
      "1935 episodes completed\n",
      "loss 5.8417863845825195\n",
      "steps done 1453780\n",
      "1940 episodes completed\n",
      "loss 5.862874507904053\n",
      "steps done 1457070\n",
      "update target\n",
      "1945 episodes completed\n",
      "loss 7.110681533813477\n",
      "steps done 1461510\n",
      "1950 episodes completed\n",
      "loss 5.837148666381836\n",
      "steps done 1465840\n",
      "1955 episodes completed\n",
      "loss 5.190023422241211\n",
      "steps done 1469640\n",
      "update target\n",
      "1960 episodes completed\n",
      "loss 5.110256195068359\n",
      "steps done 1473500\n",
      "1965 episodes completed\n",
      "loss 5.0060858726501465\n",
      "steps done 1478170\n",
      "update target\n",
      "1970 episodes completed\n",
      "loss 5.576622009277344\n",
      "steps done 1482370\n",
      "1975 episodes completed\n",
      "loss 4.865511894226074\n",
      "steps done 1486040\n",
      "1980 episodes completed\n",
      "loss 4.706281661987305\n",
      "steps done 1489970\n",
      "update target\n",
      "1985 episodes completed\n",
      "loss 6.157661437988281\n",
      "steps done 1494120\n",
      "1990 episodes completed\n",
      "loss 5.063283920288086\n",
      "steps done 1498080\n",
      "update target\n",
      "1995 episodes completed\n",
      "loss 5.672645568847656\n",
      "steps done 1501590\n",
      "2000 episodes completed\n",
      "loss 5.714937210083008\n",
      "steps done 1505890\n",
      "2005 episodes completed\n",
      "loss 4.981383323669434\n",
      "steps done 1509570\n",
      "update target\n",
      "2010 episodes completed\n",
      "loss 5.988079071044922\n",
      "steps done 1513220\n",
      "2015 episodes completed\n",
      "loss 6.48891544342041\n",
      "steps done 1516460\n",
      "2020 episodes completed\n",
      "loss 6.221263408660889\n",
      "steps done 1519780\n",
      "update target\n",
      "2025 episodes completed\n",
      "loss 5.544882774353027\n",
      "steps done 1523590\n",
      "2030 episodes completed\n",
      "loss 6.028652191162109\n",
      "steps done 1526970\n",
      "update target\n",
      "2035 episodes completed\n",
      "loss 6.384210586547852\n",
      "steps done 1530630\n",
      "2040 episodes completed\n",
      "loss 5.954961776733398\n",
      "steps done 1534080\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://n9ki0g6owl.clg07azjl.paperspacegradient.com/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "DT          = 0.5  # Time between wildfire updates            \n",
    "DTI         = 0.1  # Time between aircraft decisions\n",
    "fireEnv = ProbabilisticFireEnv(height, width)\n",
    "dronesEnv = DronesEnv(height, width, DT, DTI) \n",
    "loss = None\n",
    "i_episode = 1\n",
    "\n",
    "observation = fireEnv.reset()\n",
    "dronesEnv.reset(observation)\n",
    "\n",
    "while True:\n",
    "  # Initialize the environment and state\n",
    "  #env.reset()\n",
    "  for j in range(TRAIN_FREQ//int(2*DT/DTI)):\n",
    "\n",
    "    observation = fireEnv.step()\n",
    "\n",
    "    state_vector_1 = dronesEnv.drones[0].state\n",
    "    map_1 = dronesEnv.drones[0].observation\n",
    "    state_vector_1 = torch.tensor(state_vector_1, device=device, dtype=torch.float)\n",
    "    map_1 = torch.tensor(map_1, device=device, dtype=torch.float)\n",
    "\n",
    "    state_vector_2 = dronesEnv.drones[1].state\n",
    "    map_2 = dronesEnv.drones[1].observation\n",
    "    state_vector_2 = torch.tensor(state_vector_2, device=device, dtype=torch.float)\n",
    "    map_2 = torch.tensor(map_2, device=device, dtype=torch.float)\n",
    "\n",
    "    for i in range(int(DT/DTI)):\n",
    "      action1 = select_action(map_1, state_vector_1, steps)\n",
    "      action2 = select_action(map_2, state_vector_2, steps)\n",
    "      steps += 2\n",
    "      reward_1, reward_2 = dronesEnv.step([action1.item(), action2.item()], observation)\n",
    "\n",
    "      next_state_vector_1 = dronesEnv.drones[0].state\n",
    "      next_map_1 = dronesEnv.drones[0].observation\n",
    "\n",
    "      next_state_vector_1 = torch.tensor(next_state_vector_1, device=device, dtype=torch.float)\n",
    "      next_map_1 = torch.tensor(next_map_1, device=device, dtype=torch.float)\n",
    "\n",
    "      next_state_vector_2 = dronesEnv.drones[1].state\n",
    "      next_map_2 = dronesEnv.drones[1].observation\n",
    "\n",
    "      next_state_vector_2 = torch.tensor(next_state_vector_2, device=device, dtype=torch.float)\n",
    "      next_map_2 = torch.tensor(next_map_2, device=device, dtype=torch.float)\n",
    "\n",
    "      reward_1 = torch.tensor([reward_1], device=device)\n",
    "      reward_2 = torch.tensor([reward_2], device=device)  \n",
    "\n",
    "      memory.push(map_1, state_vector_1, action1, next_map_1, next_state_vector_1, reward_1)\n",
    "      memory.push(map_2, state_vector_2, action2, next_map_2, next_state_vector_2, reward_2)\n",
    "\n",
    "      state_vector_1 = next_state_vector_1\n",
    "      state_vector_2 = next_state_vector_2\n",
    "\n",
    "      map_1 = next_map_1\n",
    "      map_2 = next_map_2\n",
    "\n",
    "    if not fireEnv.fire_in_range(6):\n",
    "      observation = fireEnv.reset()\n",
    "      dronesEnv.reset(observation)\n",
    "\n",
    "      i_episode +=1\n",
    "      if (i_episode+1) % 5 == 0:\n",
    "        print(f'{i_episode+1} episodes completed')\n",
    "        print(f'loss {loss}')\n",
    "        print(f'steps done {steps}')\n",
    "      \n",
    "\n",
    "  if steps>=INIT_SIZE:\n",
    "    loss = optimize_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
