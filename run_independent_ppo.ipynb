{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting svgpath2mpl\n",
      "  Downloading svgpath2mpl-1.0.0-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (1.23.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from svgpath2mpl) (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (4.34.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->svgpath2mpl) (9.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->svgpath2mpl) (1.14.0)\n",
      "Installing collected packages: svgpath2mpl\n",
      "Successfully installed svgpath2mpl-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install svgpath2mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "from probabilistic_fire_env import ProbabilisticFireEnv\n",
    "from drone_env import DronesEnv\n",
    "from networks.ppo_net import PPONet\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT          = 0.5  # Time between wildfire updates            \n",
    "DTI         = 0.1  # Time between aircraft decisions\n",
    "n_actions = 2\n",
    "height = width = 100\n",
    "channels = 2\n",
    "EPISODES_PER_BATCH = 1\n",
    "TRAIN_FREQ  = 10\n",
    "SAVE_FREQ = 20\n",
    "GAMMA = 0.9\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "LAMDA = 0.9\n",
    "UPDATES = 10000\n",
    "EPSILON = 0.1\n",
    "\n",
    "EPOCHS = 10\n",
    "NUM_PROCESSES = 1\n",
    "BETA = 0.01\n",
    "TAU = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PPONet(device,  channels, height, width, n_actions).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('belief_map', 'state_vector', 'action', 'reward', 'value', 'log_policy'))\n",
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "  def __init__(self):\n",
    "    self._memory = []\n",
    "    \n",
    "  def push(self, *args):\n",
    "    \"\"\"Save a transition\"\"\"\n",
    "    self._memory.append(Transition(*args))\n",
    "\n",
    "  @property\n",
    "  def get_batch(self):\n",
    "    return self._memory\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self._memory)\n",
    "\n",
    "  def clear(self):\n",
    "    self._memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT          = 0.5  # Time between wildfire updates            \n",
    "DTI         = 0.1  # Time between aircraft decisions\n",
    "fireEnv = ProbabilisticFireEnv(height, width)\n",
    "dronesEnv = DronesEnv(height, width, DT, DTI) \n",
    "loss = None\n",
    "i_episode = 1\n",
    "SAVE_MODEL = 10\n",
    "N_DRONES = 2\n",
    "steps = 0\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1. Total loss: 0.02799837291240692\n",
      "Episode: 1. Total loss: 0.026823706924915314\n",
      "Episode: 2. Total loss: -3.6505913734436035\n",
      "Episode: 2. Total loss: 0.3167976140975952\n",
      "Episode: 3. Total loss: -1.209546446800232\n",
      "Episode: 3. Total loss: -1.0565685033798218\n",
      "Episode: 4. Total loss: -0.0018777013756334782\n",
      "Episode: 4. Total loss: 0.0006790105253458023\n",
      "Episode: 5. Total loss: 0.027159474790096283\n",
      "Episode: 5. Total loss: 0.07939529418945312\n",
      "Episode: 6. Total loss: 5.440525054931641\n",
      "Episode: 6. Total loss: 5.041927337646484\n",
      "Episode: 7. Total loss: 0.029298098757863045\n",
      "Episode: 7. Total loss: 2.3409292697906494\n",
      "Episode: 8. Total loss: -2.6780829429626465\n",
      "Episode: 8. Total loss: 0.23820964992046356\n",
      "Episode: 9. Total loss: 1.2588509321212769\n",
      "Episode: 9. Total loss: 0.38812899589538574\n",
      "saved\n",
      "Episode: 10. Total loss: 0.2658970057964325\n",
      "Episode: 10. Total loss: 0.24153049290180206\n",
      "Episode: 11. Total loss: 2.1258182525634766\n",
      "Episode: 11. Total loss: -2.454558849334717\n",
      "Episode: 12. Total loss: -1.1221046447753906\n",
      "Episode: 12. Total loss: 0.020530235022306442\n",
      "Episode: 13. Total loss: 0.026388084515929222\n",
      "Episode: 13. Total loss: -6.749690532684326\n",
      "Episode: 14. Total loss: 7.126215934753418\n",
      "Episode: 14. Total loss: -1.99852454662323\n",
      "Episode: 15. Total loss: -0.39867472648620605\n",
      "Episode: 15. Total loss: 4.5518293380737305\n",
      "Episode: 16. Total loss: -0.42539548873901367\n",
      "Episode: 16. Total loss: 6.486667633056641\n",
      "Episode: 17. Total loss: 0.4725916385650635\n",
      "Episode: 17. Total loss: -1.9869561195373535\n",
      "Episode: 18. Total loss: 0.2611043453216553\n",
      "Episode: 18. Total loss: 0.07606284320354462\n",
      "Episode: 19. Total loss: -0.4637690484523773\n",
      "Episode: 19. Total loss: -0.4592500925064087\n",
      "saved\n",
      "Episode: 20. Total loss: -0.6805782914161682\n",
      "Episode: 20. Total loss: 0.3456685245037079\n",
      "Episode: 21. Total loss: 0.39765849709510803\n",
      "Episode: 21. Total loss: -1.7519174814224243\n",
      "Episode: 22. Total loss: 1.6879873275756836\n",
      "Episode: 22. Total loss: 4.190666198730469\n",
      "Episode: 23. Total loss: -3.9676597118377686\n",
      "Episode: 23. Total loss: 1.181988000869751\n",
      "Episode: 24. Total loss: -0.053790267556905746\n",
      "Episode: 24. Total loss: 9.214749336242676\n",
      "Episode: 25. Total loss: 2.90982723236084\n",
      "Episode: 25. Total loss: 4.143246650695801\n",
      "Episode: 26. Total loss: 0.510850191116333\n",
      "Episode: 26. Total loss: -0.49515050649642944\n",
      "Episode: 27. Total loss: -11.492579460144043\n",
      "Episode: 27. Total loss: -5.826937675476074\n",
      "Episode: 28. Total loss: 5.58905553817749\n",
      "Episode: 28. Total loss: 5.30026912689209\n",
      "Episode: 29. Total loss: -6.851883888244629\n",
      "Episode: 29. Total loss: -3.7229106426239014\n",
      "saved\n",
      "Episode: 30. Total loss: 1.4594149589538574\n",
      "Episode: 30. Total loss: 8.08401870727539\n",
      "Episode: 31. Total loss: -0.0746627077460289\n",
      "Episode: 31. Total loss: -0.01406569592654705\n",
      "Episode: 32. Total loss: -11.682598114013672\n",
      "Episode: 32. Total loss: -7.472287654876709\n",
      "Episode: 33. Total loss: 8.451533317565918\n",
      "Episode: 33. Total loss: 8.09507942199707\n",
      "Episode: 34. Total loss: 7.45615816116333\n",
      "Episode: 34. Total loss: 9.609054565429688\n",
      "Episode: 35. Total loss: 0.04334232583642006\n",
      "Episode: 35. Total loss: 7.151097774505615\n",
      "Episode: 36. Total loss: 1.4396593570709229\n",
      "Episode: 36. Total loss: 2.6603665351867676\n",
      "Episode: 37. Total loss: -1.2757017612457275\n",
      "Episode: 37. Total loss: -1.647025465965271\n",
      "Episode: 38. Total loss: 4.067533493041992\n",
      "Episode: 38. Total loss: 2.5948638916015625\n",
      "Episode: 39. Total loss: 0.15680299699306488\n",
      "Episode: 39. Total loss: -5.329049110412598\n",
      "saved\n",
      "Episode: 40. Total loss: 0.023662380874156952\n",
      "Episode: 40. Total loss: -2.823997735977173\n",
      "Episode: 41. Total loss: 1.451870083808899\n",
      "Episode: 41. Total loss: -6.4475789070129395\n",
      "Episode: 42. Total loss: 0.006131375208497047\n",
      "Episode: 42. Total loss: 11.88041877746582\n",
      "Episode: 43. Total loss: 9.014405250549316\n",
      "Episode: 43. Total loss: 5.375536918640137\n",
      "Episode: 44. Total loss: 12.276379585266113\n",
      "Episode: 44. Total loss: 9.627039909362793\n",
      "Episode: 45. Total loss: 7.255305290222168\n",
      "Episode: 45. Total loss: 8.864097595214844\n",
      "Episode: 46. Total loss: 0.4106282889842987\n",
      "Episode: 46. Total loss: 6.071435451507568\n",
      "Episode: 47. Total loss: 3.4440252780914307\n",
      "Episode: 47. Total loss: 0.8367709517478943\n",
      "Episode: 48. Total loss: -6.036694049835205\n",
      "Episode: 48. Total loss: 1.6403714418411255\n",
      "Episode: 49. Total loss: 3.712735891342163\n",
      "Episode: 49. Total loss: 1.7898954153060913\n",
      "saved\n",
      "Episode: 50. Total loss: 1.8040584325790405\n",
      "Episode: 50. Total loss: 4.193943977355957\n",
      "Episode: 51. Total loss: 1.3759870529174805\n",
      "Episode: 51. Total loss: 8.67952823638916\n",
      "Episode: 52. Total loss: -3.4107837677001953\n",
      "Episode: 52. Total loss: 7.088927745819092\n",
      "Episode: 53. Total loss: 0.39613282680511475\n",
      "Episode: 53. Total loss: 0.4353158175945282\n",
      "Episode: 54. Total loss: -0.04881640896201134\n",
      "Episode: 54. Total loss: -0.41631320118904114\n",
      "Episode: 55. Total loss: -2.3893849849700928\n",
      "Episode: 55. Total loss: -2.089592218399048\n",
      "Episode: 56. Total loss: 3.5600690841674805\n",
      "Episode: 56. Total loss: 4.0336689949035645\n",
      "Episode: 57. Total loss: -5.960702419281006\n",
      "Episode: 57. Total loss: 0.1731235533952713\n",
      "Episode: 58. Total loss: 0.8532987833023071\n",
      "Episode: 58. Total loss: -5.597173690795898\n",
      "Episode: 59. Total loss: 0.2807791233062744\n",
      "Episode: 59. Total loss: 6.010907173156738\n",
      "saved\n",
      "Episode: 60. Total loss: 2.541046619415283\n",
      "Episode: 60. Total loss: 0.3093891441822052\n",
      "Episode: 61. Total loss: 13.544776916503906\n",
      "Episode: 61. Total loss: -2.136186361312866\n",
      "Episode: 62. Total loss: 1.2820122241973877\n",
      "Episode: 62. Total loss: -8.825496673583984\n",
      "Episode: 63. Total loss: 12.262511253356934\n",
      "Episode: 63. Total loss: 7.890385627746582\n",
      "Episode: 64. Total loss: 4.20819616317749\n",
      "Episode: 64. Total loss: -5.716914653778076\n",
      "Episode: 65. Total loss: 8.823410034179688\n",
      "Episode: 65. Total loss: 10.01483154296875\n",
      "Episode: 66. Total loss: 5.288461208343506\n",
      "Episode: 66. Total loss: 1.618178367614746\n",
      "Episode: 67. Total loss: 1.9168211221694946\n",
      "Episode: 67. Total loss: -3.9351885318756104\n",
      "Episode: 68. Total loss: 7.406336784362793\n",
      "Episode: 68. Total loss: 6.3885908126831055\n",
      "Episode: 69. Total loss: 0.04964785277843475\n",
      "Episode: 69. Total loss: -0.009987635537981987\n",
      "saved\n",
      "Episode: 70. Total loss: -0.29239675402641296\n",
      "Episode: 70. Total loss: 0.025333328172564507\n",
      "Episode: 71. Total loss: -1.9205268621444702\n",
      "Episode: 71. Total loss: -2.9275104999542236\n",
      "Episode: 72. Total loss: -4.880342960357666\n",
      "Episode: 72. Total loss: 9.588301658630371\n",
      "Episode: 73. Total loss: -1.3982666730880737\n",
      "Episode: 73. Total loss: 0.7003476023674011\n",
      "Episode: 74. Total loss: 0.08491698652505875\n",
      "Episode: 74. Total loss: 0.11474921554327011\n",
      "Episode: 75. Total loss: 0.054813701659440994\n",
      "Episode: 75. Total loss: -0.21948431432247162\n",
      "Episode: 76. Total loss: 10.52797794342041\n",
      "Episode: 76. Total loss: 0.952239990234375\n",
      "Episode: 77. Total loss: 3.1188583374023438\n",
      "Episode: 77. Total loss: 2.694551944732666\n",
      "Episode: 78. Total loss: 0.24610406160354614\n",
      "Episode: 78. Total loss: 11.559075355529785\n",
      "Episode: 79. Total loss: -2.5439400672912598\n",
      "Episode: 79. Total loss: 0.12138880044221878\n",
      "saved\n",
      "Episode: 80. Total loss: -3.623570442199707\n",
      "Episode: 80. Total loss: -0.2518256902694702\n",
      "Episode: 81. Total loss: 0.8347876667976379\n",
      "Episode: 81. Total loss: 0.8468964099884033\n",
      "Episode: 82. Total loss: -9.997690200805664\n",
      "Episode: 82. Total loss: 0.17645159363746643\n",
      "Episode: 83. Total loss: -4.613794803619385\n",
      "Episode: 83. Total loss: -4.33491849899292\n",
      "Episode: 84. Total loss: 3.666335344314575\n",
      "Episode: 84. Total loss: 3.0132739543914795\n",
      "Episode: 85. Total loss: 4.753147602081299\n",
      "Episode: 85. Total loss: 2.246724843978882\n",
      "Episode: 86. Total loss: 2.286018133163452\n",
      "Episode: 86. Total loss: 1.147246241569519\n",
      "Episode: 87. Total loss: 5.918638229370117\n",
      "Episode: 87. Total loss: 5.8682684898376465\n",
      "Episode: 88. Total loss: 5.8531999588012695\n",
      "Episode: 88. Total loss: 7.140003681182861\n",
      "Episode: 89. Total loss: -4.583927631378174\n",
      "Episode: 89. Total loss: -5.35811710357666\n",
      "saved\n",
      "Episode: 90. Total loss: -0.17755375802516937\n",
      "Episode: 90. Total loss: -2.281168222427368\n",
      "Episode: 91. Total loss: 3.4031035900115967\n",
      "Episode: 91. Total loss: 2.6061949729919434\n",
      "Episode: 92. Total loss: 1.6624095439910889\n",
      "Episode: 92. Total loss: -9.718935012817383\n",
      "Episode: 93. Total loss: 2.543419122695923\n",
      "Episode: 93. Total loss: 8.094086647033691\n",
      "Episode: 94. Total loss: 2.2010836601257324\n",
      "Episode: 94. Total loss: 3.624054431915283\n",
      "Episode: 95. Total loss: -8.256867408752441\n",
      "Episode: 95. Total loss: -8.829510688781738\n",
      "Episode: 96. Total loss: 3.4564170837402344\n",
      "Episode: 96. Total loss: 5.032478332519531\n",
      "Episode: 97. Total loss: 4.3669514656066895\n",
      "Episode: 97. Total loss: 1.8264884948730469\n",
      "Episode: 98. Total loss: 1.1366478204727173\n",
      "Episode: 98. Total loss: -1.3932934999465942\n",
      "Episode: 99. Total loss: -3.8357994556427\n",
      "Episode: 99. Total loss: 1.5350779294967651\n",
      "saved\n",
      "Episode: 100. Total loss: 7.997385025024414\n",
      "Episode: 100. Total loss: 9.502595901489258\n",
      "Episode: 101. Total loss: 0.7473405599594116\n",
      "Episode: 101. Total loss: 0.7795004844665527\n",
      "Episode: 102. Total loss: 9.554488182067871\n",
      "Episode: 102. Total loss: 4.612712860107422\n",
      "Episode: 103. Total loss: 0.7381469011306763\n",
      "Episode: 103. Total loss: 3.9606428146362305\n",
      "Episode: 104. Total loss: 0.27000588178634644\n",
      "Episode: 104. Total loss: -2.5978786945343018\n",
      "Episode: 105. Total loss: -4.01507568359375\n",
      "Episode: 105. Total loss: 1.2684499025344849\n",
      "Episode: 106. Total loss: 11.890899658203125\n",
      "Episode: 106. Total loss: -0.19124050438404083\n",
      "Episode: 107. Total loss: 3.3508119583129883\n",
      "Episode: 107. Total loss: 0.2895349860191345\n",
      "Episode: 108. Total loss: -5.096531867980957\n",
      "Episode: 108. Total loss: 5.258760452270508\n",
      "Episode: 109. Total loss: 2.876887321472168\n",
      "Episode: 109. Total loss: 0.9734241366386414\n",
      "saved\n",
      "Episode: 110. Total loss: 0.8894177079200745\n",
      "Episode: 110. Total loss: -0.31647735834121704\n",
      "Episode: 111. Total loss: 0.20904086530208588\n",
      "Episode: 111. Total loss: 8.354793548583984\n",
      "Episode: 112. Total loss: 0.22332967817783356\n",
      "Episode: 112. Total loss: 5.90837287902832\n",
      "Episode: 113. Total loss: -0.15936174988746643\n",
      "Episode: 113. Total loss: -1.0560376644134521\n",
      "Episode: 114. Total loss: -0.030974257737398148\n",
      "Episode: 114. Total loss: -3.350642442703247\n",
      "Episode: 115. Total loss: 1.5718419551849365\n",
      "Episode: 115. Total loss: 6.0429368019104\n",
      "Episode: 116. Total loss: 1.481863260269165\n",
      "Episode: 116. Total loss: 11.616931915283203\n",
      "Episode: 117. Total loss: -6.665201187133789\n",
      "Episode: 117. Total loss: 1.580111026763916\n",
      "Episode: 118. Total loss: 1.0379436016082764\n",
      "Episode: 118. Total loss: 1.6925268173217773\n",
      "Episode: 119. Total loss: 0.7645581364631653\n",
      "Episode: 119. Total loss: 1.0188595056533813\n",
      "saved\n",
      "Episode: 120. Total loss: 4.8984785079956055\n",
      "Episode: 120. Total loss: 0.8295385241508484\n",
      "Episode: 121. Total loss: 0.8879632949829102\n",
      "Episode: 121. Total loss: 0.4972628057003021\n",
      "Episode: 122. Total loss: 0.2539227604866028\n",
      "Episode: 122. Total loss: 0.3259398639202118\n",
      "Episode: 123. Total loss: 0.2452162355184555\n",
      "Episode: 123. Total loss: 0.27036622166633606\n",
      "Episode: 124. Total loss: 1.1928290128707886\n",
      "Episode: 124. Total loss: 0.7399644255638123\n",
      "Episode: 125. Total loss: 0.2947782576084137\n",
      "Episode: 125. Total loss: 0.6966006755828857\n",
      "Episode: 126. Total loss: -5.778806209564209\n",
      "Episode: 126. Total loss: 3.1743762493133545\n",
      "Episode: 127. Total loss: 1.4361621141433716\n",
      "Episode: 127. Total loss: 0.13404567539691925\n",
      "Episode: 128. Total loss: -0.023711472749710083\n",
      "Episode: 128. Total loss: 7.771420001983643\n",
      "Episode: 129. Total loss: 0.3600950539112091\n",
      "Episode: 129. Total loss: 0.9952871203422546\n",
      "saved\n",
      "Episode: 130. Total loss: 0.8557204008102417\n",
      "Episode: 130. Total loss: -4.39678430557251\n",
      "Episode: 131. Total loss: 0.564048707485199\n",
      "Episode: 131. Total loss: 2.309473991394043\n",
      "Episode: 132. Total loss: 1.2087695598602295\n",
      "Episode: 132. Total loss: 4.544348239898682\n",
      "Episode: 133. Total loss: 11.999002456665039\n",
      "Episode: 133. Total loss: -1.362229347229004\n",
      "Episode: 134. Total loss: 17.255605697631836\n",
      "Episode: 134. Total loss: 5.335845947265625\n",
      "Episode: 135. Total loss: 1.9926055669784546\n",
      "Episode: 135. Total loss: 1.6035925149917603\n",
      "Episode: 136. Total loss: 5.560173988342285\n",
      "Episode: 136. Total loss: -0.036291033029556274\n",
      "Episode: 137. Total loss: 8.770151138305664\n",
      "Episode: 137. Total loss: 2.2372989654541016\n",
      "Episode: 138. Total loss: -7.21262788772583\n",
      "Episode: 138. Total loss: 1.081499695777893\n",
      "Episode: 139. Total loss: -0.08733449131250381\n",
      "Episode: 139. Total loss: -0.3751899003982544\n",
      "saved\n",
      "Episode: 140. Total loss: -8.453606605529785\n",
      "Episode: 140. Total loss: 1.1200608015060425\n",
      "Episode: 141. Total loss: 5.097991943359375\n",
      "Episode: 141. Total loss: 0.24530331790447235\n",
      "Episode: 142. Total loss: 0.7673516273498535\n",
      "Episode: 142. Total loss: -1.0812833309173584\n",
      "Episode: 143. Total loss: 7.817654609680176\n",
      "Episode: 143. Total loss: 12.024629592895508\n",
      "Episode: 144. Total loss: 0.9634233117103577\n",
      "Episode: 144. Total loss: 0.3742207884788513\n",
      "Episode: 145. Total loss: 1.1722007989883423\n",
      "Episode: 145. Total loss: 1.5472432374954224\n",
      "Episode: 146. Total loss: 1.1365818977355957\n",
      "Episode: 146. Total loss: 1.3808940649032593\n",
      "Episode: 147. Total loss: -8.294242858886719\n",
      "Episode: 147. Total loss: 4.903485298156738\n",
      "Episode: 148. Total loss: 8.365800857543945\n",
      "Episode: 148. Total loss: 5.495066165924072\n",
      "Episode: 149. Total loss: 2.451848030090332\n",
      "Episode: 149. Total loss: 0.7586868405342102\n",
      "saved\n",
      "Episode: 150. Total loss: -0.19801798462867737\n",
      "Episode: 150. Total loss: 0.35940253734588623\n",
      "Episode: 151. Total loss: 0.08128181099891663\n",
      "Episode: 151. Total loss: 0.08363641053438187\n",
      "Episode: 152. Total loss: 1.6415268182754517\n",
      "Episode: 152. Total loss: 1.061273217201233\n",
      "Episode: 153. Total loss: 1.2661534547805786\n",
      "Episode: 153. Total loss: 3.9103448390960693\n",
      "Episode: 154. Total loss: -0.03691936284303665\n",
      "Episode: 154. Total loss: 6.908934593200684\n",
      "Episode: 155. Total loss: 1.1824860572814941\n",
      "Episode: 155. Total loss: 0.7227839231491089\n",
      "Episode: 156. Total loss: 1.0367474555969238\n",
      "Episode: 156. Total loss: 0.5109986662864685\n",
      "Episode: 157. Total loss: 0.3229285478591919\n",
      "Episode: 157. Total loss: 0.5747284889221191\n",
      "Episode: 158. Total loss: 0.7030403017997742\n",
      "Episode: 158. Total loss: -0.879581093788147\n",
      "Episode: 159. Total loss: 6.594137191772461\n",
      "Episode: 159. Total loss: 1.5232300758361816\n",
      "saved\n",
      "Episode: 160. Total loss: 2.015946388244629\n",
      "Episode: 160. Total loss: 4.287370681762695\n",
      "Episode: 161. Total loss: 2.364326238632202\n",
      "Episode: 161. Total loss: 2.234821081161499\n",
      "Episode: 162. Total loss: -3.2624876499176025\n",
      "Episode: 162. Total loss: -1.4174562692642212\n",
      "Episode: 163. Total loss: 0.6335977911949158\n",
      "Episode: 163. Total loss: -2.4426469802856445\n",
      "Episode: 164. Total loss: 3.4280059337615967\n",
      "Episode: 164. Total loss: 0.35930895805358887\n",
      "Episode: 165. Total loss: 3.7345221042633057\n",
      "Episode: 165. Total loss: 0.9310494065284729\n",
      "Episode: 166. Total loss: -3.7931296825408936\n",
      "Episode: 166. Total loss: 9.498932838439941\n",
      "Episode: 167. Total loss: 1.148687481880188\n",
      "Episode: 167. Total loss: 0.15222884714603424\n",
      "Episode: 168. Total loss: 0.9567777514457703\n",
      "Episode: 168. Total loss: -7.520650863647461\n",
      "Episode: 169. Total loss: 0.6704179048538208\n",
      "Episode: 169. Total loss: 6.875053882598877\n",
      "saved\n",
      "Episode: 170. Total loss: 1.0155049562454224\n",
      "Episode: 170. Total loss: 0.5364166498184204\n",
      "Episode: 171. Total loss: 0.49304020404815674\n",
      "Episode: 171. Total loss: 1.6342196464538574\n",
      "Episode: 172. Total loss: 0.8466607928276062\n",
      "Episode: 172. Total loss: 0.7683524489402771\n",
      "Episode: 173. Total loss: 0.2552022635936737\n",
      "Episode: 173. Total loss: 0.6099837422370911\n",
      "Episode: 174. Total loss: 0.35003817081451416\n",
      "Episode: 174. Total loss: -3.8022689819335938\n",
      "Episode: 175. Total loss: 0.438112735748291\n",
      "Episode: 175. Total loss: 0.3428463935852051\n",
      "Episode: 176. Total loss: 0.09344439953565598\n",
      "Episode: 176. Total loss: 14.093297004699707\n",
      "Episode: 177. Total loss: 2.75608491897583\n",
      "Episode: 177. Total loss: -1.7106600999832153\n",
      "Episode: 178. Total loss: 10.453330993652344\n",
      "Episode: 178. Total loss: 0.8695681691169739\n",
      "Episode: 179. Total loss: 0.8984885811805725\n",
      "Episode: 179. Total loss: -0.13003313541412354\n",
      "saved\n",
      "Episode: 180. Total loss: -0.17062871158123016\n",
      "Episode: 180. Total loss: 2.6984033584594727\n",
      "Episode: 181. Total loss: -8.57672119140625\n",
      "Episode: 181. Total loss: 0.659480631351471\n",
      "Episode: 182. Total loss: 1.121776819229126\n",
      "Episode: 182. Total loss: 0.9239519238471985\n",
      "Episode: 183. Total loss: -3.6360881328582764\n",
      "Episode: 183. Total loss: 14.121562004089355\n",
      "Episode: 184. Total loss: 7.137996673583984\n",
      "Episode: 184. Total loss: 9.839585304260254\n",
      "Episode: 185. Total loss: -9.346491813659668\n",
      "Episode: 185. Total loss: 0.8026698231697083\n",
      "Episode: 186. Total loss: 9.998115539550781\n",
      "Episode: 186. Total loss: 5.728740692138672\n",
      "Episode: 187. Total loss: 8.126750946044922\n",
      "Episode: 187. Total loss: 1.0961806774139404\n",
      "Episode: 188. Total loss: -3.2920374870300293\n",
      "Episode: 188. Total loss: 0.4631425142288208\n",
      "Episode: 189. Total loss: 3.5224545001983643\n",
      "Episode: 189. Total loss: 0.14429433643817902\n",
      "saved\n",
      "Episode: 190. Total loss: -0.5050330758094788\n",
      "Episode: 190. Total loss: 0.4705348312854767\n",
      "Episode: 191. Total loss: 0.42762163281440735\n",
      "Episode: 191. Total loss: -0.055295247584581375\n",
      "Episode: 192. Total loss: 0.3763122260570526\n",
      "Episode: 192. Total loss: -0.2746121287345886\n",
      "Episode: 193. Total loss: -0.029774736613035202\n",
      "Episode: 193. Total loss: 4.661226749420166\n",
      "Episode: 194. Total loss: -5.459677219390869\n",
      "Episode: 194. Total loss: 0.28706982731819153\n",
      "Episode: 195. Total loss: 0.7771773338317871\n",
      "Episode: 195. Total loss: 1.3200488090515137\n",
      "Episode: 196. Total loss: 4.85206937789917\n",
      "Episode: 196. Total loss: -1.0938555002212524\n",
      "Episode: 197. Total loss: 9.139890670776367\n",
      "Episode: 197. Total loss: -2.2663917541503906\n",
      "Episode: 198. Total loss: 1.3594567775726318\n",
      "Episode: 198. Total loss: 0.2961690425872803\n",
      "Episode: 199. Total loss: 2.5102250576019287\n",
      "Episode: 199. Total loss: 7.304313659667969\n",
      "saved\n",
      "Episode: 200. Total loss: -0.5107423067092896\n",
      "Episode: 200. Total loss: -0.3783354163169861\n",
      "Episode: 201. Total loss: 0.6298404932022095\n",
      "Episode: 201. Total loss: 3.774003505706787\n",
      "Episode: 202. Total loss: 0.662712812423706\n",
      "Episode: 202. Total loss: 0.49401623010635376\n",
      "Episode: 203. Total loss: 0.9778680801391602\n",
      "Episode: 203. Total loss: 1.9877310991287231\n",
      "Episode: 204. Total loss: 0.9968116283416748\n",
      "Episode: 204. Total loss: 0.7508113980293274\n",
      "Episode: 205. Total loss: 4.975551128387451\n",
      "Episode: 205. Total loss: 1.037108302116394\n",
      "Episode: 206. Total loss: 3.432868242263794\n",
      "Episode: 206. Total loss: 0.3305045962333679\n",
      "Episode: 207. Total loss: 0.5793957710266113\n",
      "Episode: 207. Total loss: 0.3923354744911194\n",
      "Episode: 208. Total loss: 7.589295864105225\n",
      "Episode: 208. Total loss: 18.927064895629883\n",
      "Episode: 209. Total loss: 0.1698518842458725\n",
      "Episode: 209. Total loss: 1.3685848712921143\n",
      "saved\n",
      "Episode: 210. Total loss: -12.912718772888184\n",
      "Episode: 210. Total loss: 0.05419456586241722\n",
      "Episode: 211. Total loss: 0.991916298866272\n",
      "Episode: 211. Total loss: 7.206823348999023\n",
      "Episode: 212. Total loss: 1.7109471559524536\n",
      "Episode: 212. Total loss: 2.2152462005615234\n",
      "Episode: 213. Total loss: 16.980667114257812\n",
      "Episode: 213. Total loss: 3.3728690147399902\n",
      "Episode: 214. Total loss: -0.010286862030625343\n",
      "Episode: 214. Total loss: 2.589587688446045\n",
      "Episode: 215. Total loss: 0.7831550240516663\n",
      "Episode: 215. Total loss: -3.062638759613037\n",
      "Episode: 216. Total loss: 0.6570980548858643\n",
      "Episode: 216. Total loss: 0.7812120914459229\n",
      "Episode: 217. Total loss: 0.8417845964431763\n",
      "Episode: 217. Total loss: 0.2597859799861908\n",
      "Episode: 218. Total loss: 1.068065881729126\n",
      "Episode: 218. Total loss: 0.5711755752563477\n",
      "Episode: 219. Total loss: 0.5096014738082886\n",
      "Episode: 219. Total loss: 0.2974223792552948\n",
      "saved\n",
      "Episode: 220. Total loss: -0.43714526295661926\n",
      "Episode: 220. Total loss: -3.451718330383301\n",
      "Episode: 221. Total loss: 1.6836471557617188\n",
      "Episode: 221. Total loss: 0.23218481242656708\n",
      "Episode: 222. Total loss: 0.7050328254699707\n",
      "Episode: 222. Total loss: -3.787047863006592\n",
      "Episode: 223. Total loss: 1.8818401098251343\n",
      "Episode: 223. Total loss: 1.7424321174621582\n",
      "Episode: 224. Total loss: 0.8016974925994873\n",
      "Episode: 224. Total loss: 7.30403470993042\n",
      "Episode: 225. Total loss: 0.6854838728904724\n",
      "Episode: 225. Total loss: 2.612804651260376\n",
      "Episode: 226. Total loss: 0.4252990186214447\n",
      "Episode: 226. Total loss: 0.8812284469604492\n",
      "Episode: 227. Total loss: 1.1327894926071167\n",
      "Episode: 227. Total loss: 0.4202689826488495\n",
      "Episode: 228. Total loss: -5.744282245635986\n",
      "Episode: 228. Total loss: 1.6597771644592285\n",
      "Episode: 229. Total loss: 1.0576411485671997\n",
      "Episode: 229. Total loss: 12.004349708557129\n",
      "saved\n",
      "Episode: 230. Total loss: 0.6999339461326599\n",
      "Episode: 230. Total loss: -7.811563014984131\n",
      "Episode: 231. Total loss: 5.360694408416748\n",
      "Episode: 231. Total loss: 29.422590255737305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jeremy/Desktop/projects/notebooks/Distributed Wildfire Surveillance/run_independent_ppo.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/run_independent_ppo.ipynb#W6sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m         total_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/run_independent_ppo.ipynb#W6sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m         torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m0.5\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/run_independent_ppo.ipynb#W6sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m         optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/run_independent_ppo.ipynb#W6sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpisode: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Total loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i_episode, total_loss))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jeremy/Desktop/projects/notebooks/Distributed%20Wildfire%20Surveillance/run_independent_ppo.ipynb#W6sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m memory[d]\u001b[39m.\u001b[39mclear()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    158\u001b[0m          grads,\n\u001b[1;32m    159\u001b[0m          exp_avgs,\n\u001b[1;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    162\u001b[0m          state_steps,\n\u001b[1;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m func(params,\n\u001b[1;32m    214\u001b[0m      grads,\n\u001b[1;32m    215\u001b[0m      exp_avgs,\n\u001b[1;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    218\u001b[0m      state_steps,\n\u001b[1;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py:307\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    305\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    306\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    309\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = fireEnv.reset()\n",
    "dronesEnv.reset(seed)\n",
    "\n",
    "memory = ReplayMemory()\n",
    "state_vectors = [None]*N_DRONES\n",
    "maps = [None]*N_DRONES\n",
    "steps_for_episode = 0 \n",
    "\n",
    "while True:\n",
    "    \n",
    "    for j in range(TRAIN_FREQ//int(2*DT/DTI)):\n",
    "\n",
    "        observation = fireEnv.step()\n",
    "        \n",
    "        for d in range(N_DRONES):\n",
    "\n",
    "            state_vectors[d] = dronesEnv.drones[d].state\n",
    "            maps[d] = dronesEnv.drones[d].observation\n",
    "\n",
    "            state_vectors[d] = torch.tensor(state_vectors[d], device=device, dtype=torch.float)\n",
    "            maps[d] = torch.tensor(maps[d], device=device, dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(int(DT/DTI)):\n",
    "            \n",
    "            steps += 1\n",
    "\n",
    "            logits = [None]*N_DRONES\n",
    "            values = [None]*N_DRONES\n",
    "            actions = [None]*N_DRONES\n",
    "            old_m = [None]*N_DRONES\n",
    "            old_log_policy = [None]*N_DRONES\n",
    "            rewards = [None]*N_DRONES\n",
    "\n",
    "            for d in range(N_DRONES):\n",
    "\n",
    "                logits[d], values[d] = model(maps[d], state_vectors[d])\n",
    "                \n",
    "                policy = F.softmax(logits[d], dim=1)\n",
    "            \n",
    "                old_m[d] = Categorical(policy)\n",
    "    \n",
    "                actions[d] = old_m[d].sample()\n",
    "            \n",
    "                old_log_policy[d] = old_m[d].log_prob(actions[d])\n",
    "\n",
    "\n",
    "            rewards = dronesEnv.step(actions, observation)\n",
    "            memory.push(maps[0], state_vectors[0], actions[0], rewards[0], values[0], old_log_policy[0])\n",
    "            \n",
    "            for d in range(N_DRONES):\n",
    "\n",
    "                state_vectors[d] = dronesEnv.drones[d].state\n",
    "                maps[d] = dronesEnv.drones[d].observation\n",
    "\n",
    "                state_vectors[d] = torch.tensor(state_vectors[d], device=device, dtype=torch.float)\n",
    "                maps[d] = torch.tensor(maps[d], device=device, dtype=torch.float)\n",
    "\n",
    "            if done:\n",
    "\n",
    "                if i_episode % SAVE_MODEL == 0:\n",
    "                    file_path = f'./ppo_weights.pt'\n",
    "                    torch.save(model.state_dict(), file_path)\n",
    "                    print('saved')\n",
    "\n",
    "           \n",
    "                _, next_value, = model(maps[0], state_vectors[0])\n",
    "\n",
    "                next_value = next_value.squeeze()\n",
    "                \n",
    "                batch  = Transition(*zip(*memory.get_batch))\n",
    "\n",
    "\n",
    "                old_log_policies_batch = torch.cat(batch.log_policy).detach()\n",
    "            \n",
    "\n",
    "                actions_batch = torch.cat(batch.action)\n",
    "\n",
    "\n",
    "                value_batch = torch.cat(batch.value).detach()\n",
    "            \n",
    "\n",
    "                belief_map_batch = torch.cat(batch.belief_map)\n",
    "\n",
    "\n",
    "                state_vector_batch = torch.cat(batch.state_vector)\n",
    "\n",
    "\n",
    "                reward_batch = batch.reward \n",
    "                \n",
    "                gae = 0\n",
    "                R = []\n",
    "\n",
    "                for value, reward in list(zip(value_batch, reward_batch))[::-1]:\n",
    "                    gae = gae * GAMMA * TAU\n",
    "                    gae = gae + reward + GAMMA * next_value.detach() - value.detach()\n",
    "                    next_value = value\n",
    "                    R.append(gae + value)\n",
    "\n",
    "                R = R[::-1]\n",
    "                R = torch.cat(R).detach()\n",
    "                    \n",
    "                advantages = R - value_batch.squeeze()\n",
    "                indices = np.arange(len(memory))\n",
    "                indices_split = np.array_split(indices, BATCH_SIZE)\n",
    "                \n",
    "                for e_i in range(EPOCHS):\n",
    "                    indice = torch.randperm(len(memory))\n",
    "                 \n",
    "                    for b_i in range(len(memory)//BATCH_SIZE):\n",
    "                        batch_indices = indice[b_i*(len(memory)//BATCH_SIZE): (b_i+1) *(len(memory)//BATCH_SIZE)]\n",
    "                        logits, value = model(belief_map_batch[batch_indices], state_vector_batch[batch_indices])\n",
    "                        new_policy = F.softmax(logits, dim=1)\n",
    "                        new_m = Categorical(new_policy)\n",
    "                        new_log_policy = new_m.log_prob(actions_batch[batch_indices])\n",
    "                        ratio = torch.exp(new_log_policy - old_log_policies_batch[batch_indices])\n",
    "                        \n",
    "                        actor_loss = -torch.mean(\n",
    "                            torch.min(ratio * advantages[batch_indices],\n",
    "                                torch.clamp(ratio, 1.0 - EPSILON, 1.0 + EPSILON) *\n",
    "                                advantages[batch_indices]\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        critic_loss = F.smooth_l1_loss(R[batch_indices], value.squeeze())\n",
    "                        entropy_loss = torch.mean(new_m.entropy())\n",
    "                        total_loss = actor_loss + critic_loss - BETA * entropy_loss\n",
    "                        optimizer.zero_grad()\n",
    "                        total_loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "                        optimizer.step()\n",
    "\n",
    "                print(\"Episode: {}. Total loss: {}\".format(i_episode, total_loss))\n",
    "                memory.clear()\n",
    "                i_episode += 1\n",
    "                seed = fireEnv.reset()\n",
    "                dronesEnv.reset(seed)\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
